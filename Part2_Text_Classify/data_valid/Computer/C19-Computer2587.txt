软件学报
JOURNAL OF SOFTWARE 
1999年 第10卷 第5期 Vol.10 No.5 1999



三维场景建模的全景外极面图像分析方法
朱志刚　徐光右　 林学言
摘要　文章提出由非精确摄像机运动下的图像序列建立3D环境模型的全景外极面图像方法,实现了 无特征提取的时空纹理方向精确估计、深度边界确定和遮挡恢复算法.该方法推广并结合了 外极面图像方法和全景图像方法,避免了现有运动分层方法迭代过程中的局部最小化问题,具 有计算和存储效率高、适应性强、算法鲁棒性好的优点.建立的自然景物的真实感三维环境 模型,可用于机器人全局定位的自然路标提取和真实环境虚拟再现的图像合成.
关键词　虚拟化现实,外极面图像,全景图像,运动遮挡,景物建模. 
中图法分类号　TP391
　　运动序列理解是建立环境三维模型的主要方法之一.长运动序列分析通过增加时域范围（序 列图像的帧数）来提高计算的精度.但若运动复杂,则轨迹跟踪变得异常困难.外极面图像（e pipolar plane image,简称EPI）的方法［1］假设运动恒定,因此可将运动分析转化 为二维EPI上轨迹线的提取,但由于对运动的要求过于苛刻,限制了它的实际应用.Factorizat ion的方法［2,3］利用多帧图像上对应特征点的冗余信息,通过奇异值分解的方法计 算运动和结构,但需要假设正交投影成像模型,并需找出多幅图像上对应的特征点.为了达到 快速3D计算,有的研究人员通过精确控制摄像机运动来避免运动估计和对应问题.Dilmia和Tr eveli［4］通过控制平移运动的精度,从时空梯度信息中获得不同质量的深度信息,但 要求摄像机达到0.1mm的运动精度；Murry［5］通过精确旋转摄像机,采用时空图像分 析技术获得深度,但用简洁的方法只获得一条中心扫描线上的3D信息.
　　增加空域范围会包含多个运动/深度区域,因此需解决多运动分割这一困难的问题.在一般的 运动情况下,完全3D运动和深度计算有困难且为病态问题.目前,比较成功的方法是将多图像 运动近似为平面仿射变换［6］,即两幅图像之间几个深度层的运动符合平面仿射变换 ,这样做,实际上是对运动和景物的近似.Sawhney等人［7］提出的带射影深度的运动 估计模型,则假设了分层区域数、配准误差、各点深度离射影平面的距离综合最小的最小描 述长度（MDL）约束.这类方法的优点是无需进行特征提取,但其缺点是：(1) 计算量大；(2) 深度变化最小的假设和分层区域最少的假设不一定合理；(3) 由于采用最小化方法,可能会 导致局部最小而达不到正确的结果.
　　大坂大学的Zheng和Tsuji等人［8］利用多次观察生成的全景图像来实现全局定位.为 避免一般的由运动到结构问题的困难,全景图像的方法采用不同于一般的运动序列配准的方 法.假定机器沿路径做平滑的平面运动,且摄像机垂直于运动方向.在每幅图像中抽取某一列 组成一幅时空全景图像(panoramic view image,简称PVI),不同的列位置上可生成不同的全 景图像.通过两个不同的全景图像匹配,可获取2.5D全景表示.全景图像方法有其显著的优点 ：(1) PVI提供了大视野的2D图像,可用于全局环境建模.(2) 3D时空图像序列压缩为2D空城 图像表示,是一个高效、易存取的表示方式.(3) PVI在水平方向上为平行投影,更便于全局定 位.其不足和仍存在的问题是：(1) 难以快速、可靠地获取深度.从Tsuji等人的研究过程来 看,基于匹配和基于相关的方法均未很好地解决这一问题.(2) 丢失一些重要的信息,如,在有 的视点上可见的信息在全景图像上丢失了,近距离物体图像分辨率降低了或丢失了.(3) 在室 外的道路上要求平稳运动是不合理的,在行驶过程中会因为道路不平整或稳定性不佳而导致 图像抖动.
　　真实环境中不精确运动下的全景图像生成和深度信息获取,仍是待研究的问题.我们提出了解 决上述问题的系统方案［9］,本文着重研究解决第(1)和第(2)问题的方法,问题(3)的 解决方法已另文给出［10］.
1　全景外极面图像
　　本文提出一个可用于实际环境建模的非精确运动模型,即已知的平面运动加上未知的任意抖 动(如图1(a)所示),摄像机光轴垂直于主运动方向,而对景物的3D结构无任何限制.这种模型 适合于由移动车体上拍摄的运动序列建立自然环境模型的场合.通过稳定图像,可有效地将复 杂运动和复杂3D景物参数分开［9,10］.图像稳定后相当于车体沿着平直的道路平滑 地移动.不妨设摄像机的OX轴平行于地面,并沿着运动的方向,设车体以速度-V(V＞0 )匀速运动(相对地,景物中的物体以速度V平移),在这种设置下,空间点P的轨迹(x,y,t)就被 约束到平行于x轴的扫描线上.透视成像可表示为
　　(1)
其中(X,Y,Z)表示P点在时刻t=0时的三维坐标.图像稳定的作用在于两种有意义的二维时空截 面图像--全景图像(PVI)和外极面图像(EPI)可在真实环境的图像序列中获得(如图1( a)所示).其中,前者为三维时空图像中平行于y-t的截面,后者为平行于x-t的截面.在本 文的方法中,每个运动序列获取一幅PVI,对应于PVI的每条水平线,均有一幅EPI.

　　将摄像机用三脚架固定在轿车上,在较平坦的广场上运动获得清华大学主楼的图像序列,数字 化后,图像的数据量为128(行)×128(列)×1024(帧),图像获取频率为19帧/s.主楼图像 序列大约有1个像素左右的抖动.采用基于运动轨迹平滑的运动滤波和图像稳定,可以获得较 好的全景图像和外极面图像(如图2中各图像的边缘).PVI相当于在y方向透视投影而在x 方向平行投影的结果,它基本上反映了侧面景物的表面特性（如图2(a)所示)；而在EPI中, 由于运动及景物空域特征所形成的方向性纹理,则反映了景物中物体的深度(如图2(b)所示 ).原图像的一个特征点p(x,y)在EPI上对应于一条直线轨迹线,它的斜率与景物点P(X,Y, Z)的深度D成反比,即D=Z=f(V)/(v),其中v=(dx)/(dt)是直线轨迹线 的斜率.图像稳定中的运动滤波（分解）正是利用了这一性质［9］.
在传统的EPI处理中,需要对xt图像上的每一点进行处理,计算量很大.在本文中,只以某二 维PVI上各点为中心,有选择地分析EPI区域即可得出较完整的深度信息（如图1(b)所示）. 这种方法是将全景图像和外极面图像提供的信息进行综合,故称为全景外极面图像分析方法. 它分为6个步骤：深度可测图计算、多方向检测、运动边界定位、深度内插、被遮挡物体的 恢复以及深度分层表示.首先从全景图像IPVI(y,t)上,可计算出对应于全景图PVI 的深度可测图
B(y,t)=Gt(y,t) - Gy(y,t),(2)
其中Gt(y,t),Gy(y,t)分别为PVI上该点处水平方向和垂直方向的梯度.因为水平边 的光流存在孔径效应问题,而均匀区域无法检测出光流,因此,对于无梯度的均匀区域,可度量 性为0,垂直梯度超过水平梯度的点,可度量性为负；反之,水平梯度超过垂直梯度值越大,可 度量性越好.图3的深度可测图对应于图2(a)的全景图像.



(a) 全景图像


(b) 外极面图像
图2


图3　深度可测图
　　全景外极面图像分析方法将3D时空图像的处理降为对2D图像的处理,具有较高的计算效率. 在PVI上计算出深度可测图B(y,t)后,对每一个y坐标对应的外极面图像的基本处理是独立 的,设图像序列大小为W（宽）×H（高）×F（帧）,如果有H个并行处理器,则可同时完成H幅 W×F的外极面图像的处理.
2　多方向时空纹理检测
　　本文设计了一个大窗口方向检测算子GFOD(Guassain-Fourier orientation detector), 来检测EPI上时空纹理的方向.时空高斯窗口定义为,其Fourier变换为 .在时空纹理图像上乘以高斯窗口,以一阶运动和单深度形成的单方向纹理为例,表示为
g(x,t)=f(x-vt)w(x,t).(3) 
推导可得其Fourier变换:

布在直线ξ=- (1)/(v)ω上,通过Fourier频谱图像上对该直线的检测,可以求出时空纹理的方 向,从而获得对应点的深度值.使用高斯窗口后,离中心点越远的纹理对方向频谱的贡献越小, 从而可以照顾到运动边界的精确定位.同时,对单方向纹理和方向不很接近的多方向纹理的方 向检测精度没有很大的影响；对方向很接近的多方向纹理,原频域图像上明显的多方向直线 分布会因平滑而界限不清,但由于离检测中心点越近的纹理对频谱的能量贡献越大,从而倾向 于正确方向的检测.
　　在对应于PVI每一垂直坐标y处的外极面图像IEPI(x,t)上,只在PVI对应 的x位置（一般为x=0）上,找出位置ti,使B(y,ti)＞Tb（一般取≥2）.选择合适的窗 口大小m×m,如m=64, 则σ2=(m-1)/(4).用GFOD计算不同深度的方向角的算法 如下：
　　(1) 以(x,ti)为中心计算进行Gauss-Fouier变换得到G（ξ,ω）,为提升高频分量, 能量谱计算为

其中φ对应于xt空间轨迹线的方向角（0～π）,φ=0～(π)/(2)时为 静止景物,φ∈(π)/(2),π时为运动物体.［r1,r2］为带通 滤波器的低、高频范围.定义方向能量分布图Pd(φ,t)为各个时刻方向直方图Pd(φ)列 向量组成的图像.
　　(3) 检测多峰值Pd(θκ),其对应角θκ(k=1,...,K)表示不同的图像运动方向.K=1时 ,表示窗口内没有运动边界（深度不连续处）.K≥2时,表示窗口内存在运动边界.
　　图4显示了对应于图2全景图第1条水平线（y=64）的EPI处理结果.图中第1行为EPI的处 理区域I(x,t),第2行为对应块的Fourier频谱P(ξ,ω),第3行为各对应块中心的方向能 量分布直方图Pd(φ),第4行为对应于EPI的方向能量分布图像Pd(φ,t),第5行为对 应于EPI的方向角(用高度图表示).在第1行中,用黑白相间的直线段表示各对应块中心的 纹理方向.第4行方向能量分布图像中的白线表示该处为无纹理或弱纹理区.


图4　方向估计和深度边界定位
3　运动边界定位
　　虽然使用高斯窗口能同时兼顾方向检测精度和定位精度,但仍不能完全准确定位,因为当运动 边界包含在检测窗口内时,就可能产生多方向.由于非刚体物体,如树叶、草丛的“抖动”和 摄像机的抖动难以彻底消除,故不能严格保证灰度的时域同一性,采用轨迹线跟踪的方法易失 败.因此,在用GFOD算子检测出多个方向后,沿各方向采用了多尺度窗口的灰度/梯度一致 性的比较判断,选择一致性最好的为此处的方向.我们只分析双方向的情况,多方向的判别与 双方向的判别相似.
　　已知两个方向,θ1＞θ2,即θ1对应于近距离,θ2对应于远距离物体,在半径为R 的圆形窗口内,以(x0,t0)为中心分别沿θ1和θ2方向,在正负两个方向上度量代表 灰度不一致性的方差值C＋（θk,R）和C－（θk,R）(k=1,2).
C±(θk,R)=(1)/(R)R)/(r=1［I(±r,θk)］2-Ｉ2±(θk,R).　　(7)
　　(8)
则应选择的方向角为
.　　(9)
其中由远变近（遮挡）时选择E－(θ2,R),由近到远（重现）时选择E＋(θ2,R).
　　为了处理物体图像在时域持续较短的情况,采用多尺度的窗口度量灰度一致性度量E(θk, Ri),i=1,2,3,...,k=1,2.用多个不同大小的Ri（如i=1,2,3）,选择灰度一致性度量之 差较大的Ri作为方向选择的合理窗口半径.定义比值
　　(10)
并设p=argmaxi(Di),那么,如果E(θ1,Rp)＜E±（θ2,R p),则选择θ1;否则,选择θ2.“±” 选择同上.
　　为了得到致密的运动方向（深度）,对无纹理的区域采用合理的内插方法.在两个可度量出方 向角θ1,θ2的时刻t1,t2之间的均匀区域,内插值定义如下：深度“连续”,将中间 线性内插；深度不连续,将中间内插为远处的深度,因为很可能是近处物体遮挡在远处物体的 无纹理区.有些错误可以通过全景图上空域纹理和深度信息的融合加以修正.
　　图5显示了主楼图像序列的空域滤波后的深度图.图中的深度图是直接将方向角θ的值用亮度 形式表示,距离D越近,图像速度v越大,亮度θ越大（D=f(V)/(v),v=tanθ）.在 图5(a)中,叠加在PVI上的黑线表示了深度边界（运动边界）,可以发现对树和楼房之间, 楼房不同深度之间有较精确的深度边界.


(a) 覆盖深度边界的全景图


(b) 空域滤波后的深度图
图5　全景图的灰度图和深度图
4　遮挡恢复算法
　　由于PVI上只保留了一个视角的信息,因此,在有些视点的原始图像上能看到的景物在PVI 上丢失了.我们通过遮挡关系的分析,将其从其他时空位置的图像信息中补充上.具体算法为( 如图6所示)：(1) 找出遮挡或重现时的深度边界点t0及远、近景物的方向角θ1,θ2. (2) 确定待恢复时空景物段的x位置和时间起止点ts,te（帧）：在遮挡时x＜0,复 现时x＞0,时域起始点ts,te取决于方向角θ1,θ2以及在第t帧左右的景物的方向角 及遮挡关系.由此得到了由顶点p0(x0,t0),ps(x,ts),pe(x,te)决定的三角形 遮挡区.(3) 确定遮挡区p0pspe的类型.严格地讲,该区域内的方向可能具有复杂的情 况,为简单起见,目前只将其分为两种类型：远景遮挡区OCCLUDED（同一深度）和侧面区SI DE（渐变深度）,其中远景遮挡区的方向角取θ1,侧面区的方向角取θ1～θ2之 间的线性内插.在两种类型假设下,分别度量在三角区域内沿“轨迹线”方向总的灰度一致性 （参见公式（7））,由此判断该区域属于哪种类型,从而在点p0插入一段时空图像psp e.


图6　被遮挡的恢复和近距离分辨率的恢复 
　　对于近距离的物体（v＞1时）,在PVI上损失了原图像的分辨率,因此可根据图像速度的 大小,在x方向上取相应长度的段,恢复原图像的分辨率.而对于远距离物体（v＞1）,PVI 上时间采样率高于单幅图像的空域采样率,仍保留高的时域采样信息.图6中EPI中心轴不 同粗细的黑线表示了所取信息的长度.
5　结束语
　　为了达到有效的3D建模,本文对运动作合理的假设,提出了新的方法,取得了实际的结果.本 文在全景图像和外极面图像的结合上,提出了大窗口GFOD算子和灰度一致性比较度量方法, 避免了特征对应、取阈值等问题,对具有不精确对应、复杂的室外纹理结构具有明显的适应 性,因此在算法上改善了外极面图像轨迹线跟踪、时空图像小窗口局部方向检测的方法和全 景图像对应方法的不足.由于只对代表大部分信息的极少的数据（即全景外极面图像）进行 处理,且具有并行性,因此可以根据不同的应用达到实时或准实时.
本文研究得到国家863高科技项目基金和国防科技预研基金资助.
作者朱志刚,1964年生,博士,副教授,主要研究领域为计算机视觉,图像处理,虚拟现实,智能 机器人.
　　徐光右,1940年生,教授,博 士生导师,主要 研究领域为计算机视觉,分布式多媒体,人机交互技术.
　　林学言　,1940年生,教授, 主要研究领域为计算机视觉,模式识别,智能机器人.
本文通讯联系人：朱志刚,北京 100084,清华大学计算机科学与技术系
作者单位：（清华大学计算机科学与技术系　北京　100084）
           E-mail: zhuzhg@mail.tsinghua.edu.cn
参考文献
　[1]　Baker H H, Bolles R C. Generalizing epipolar-plane image analy sis on the spatio-temporoal surface. In: Rosenfeld A, Ahuja N, Huang T eds. Pro ceedings of IEEE Computer Vision and Pattern Recognition. Los Alamitos, CA: IEEE Computer Society Press, 1988. 2～9
　[2]　Costeira J, Kanade T. A multi-body factorization method for motion a nalysis. In: Weiner B ed. Proceedings of IEEE the 5th International Conference o n Computer Vision. Los Alamitos, CA: IEEE Computer Society Press, 1995. 1071～107 6
　[3]　Tomasi C, Kanade T. Shape and motion from image streams under orthogr aphy: a factorization method. International Journal of Computer Vision, 1992,9(2 ):137～154
　[4]　Dalmia A K, Trivedi M. High speed extraction of 3D structure of selec table quality using a translating camera. Computer Vision and Image Understandin g, 1996,64(1):97～110
　[5]　Murray D W. Recovering range using virtual multicamera stereo. Comput er Vision and Image Understanding, 1995,61(2):285～291
　[6]　Wang J, Adelson E H. Representation moving images with layers. IEEE T ransactions on Image Processing, 1994,3(5):625～638
　[7]　Sawhney H S, Ayer S. Compact representation of videos through d ominant and multiple motion estimation. IEEE Transactions on Pattern Analysis an d Machine Intelligence, 1996,18(8):814～830
　[8]　Zheng J Y, Barth M, Tsuji S. Qualitative route scene description usin g autonomous landmark detection. In: Tsuji S, Kak A, Eklundh J eds. Proceedings of IEEE the 3rd International Conference on Computer Vision. Osaka, Japan: IEEE Computer Society Press, 1990. 558～562
　[9]　朱志刚.视觉导航中环境建模的研究［博士学位论文］.北京:清华大学计 算机系,1997
(Zhu Zhi-gang. Environment modeling for visual navigation ［Ph.D. Thesis］. Bei jing: Tsinghua University, 1997)
　[10]　杨雨东,徐光礻　右,朱志刚.2.5维帧间运动估计方 法,清华大学学报(自然科学版),1997,37(9):78～81
(Yang Yu-dong, Xu Guang-you, Zhu Zhi-gang. 2.5 D inter-frame motion estimati on method. Journal of Tsinghua University, 1997,37(9):78～81)
本文1997-11-24收到原稿,1998-05-08收到修改稿
