软件学报
JOURNAL OF SOFTWARE
1999年 第10卷 第7期　No.7 Vol.10 1999



多层前向网络的交叉覆盖设计算法
张　铃　张　钹　殷海风
　　摘要　文章根据多层前向权、阈值神经网络的设计原则,将设计过程分成两步进行:先用尽可能少的领域将样本中的各类分隔开来,然后再用作者提出的交叉覆盖算法进行网络设计.文章给出两个很有代表性的模拟例子,一个是平面上两根螺线的分离问题,另一个是“无穷样本学习”的例子.模拟结果证明了此方法的有效性.
　　关键词　多层神经网络,设计原则,交叉覆盖算法.
　　中图法分类号　TP18
An Alternative Covering Design Algorithm of Multi-layer Neural Networks
ZHANG Ling1,3　ZHANG Bo2,3　YIN Hai-feng1
1(Institute of Artificial Intelligence Anhui University Hefei 230039)
2(Department of Computer Science and Technology Tsinghua University Beijing 100084)
3(Laboratory of Intelligent Technology and Systems Tsinghua University Beijing 100084)
　　Abstract　In this paper, the authors present a new principle for designing a sort of multi-layer weight-sum-and -threshold neural networks. The design process consists of two steps. First, each class of the given training samples is covered by using neighbor coverings as less as possible. Then a neural network is specifically designed by an approach called alternative covering algorithm. The simulation results of two representative hard classification problems are shown. One is so called “two spirals separation” problem, the other is “the learning problem of infinitetraining samples”. These simulation results are given to illustrate the effectiveness of the new method.
　　Key words　Multi-layer neural network, principle for design, alternative covering algorithm.
　　在文献［1］中,我们利用M-P神经元模型的几何意义,给出一种设计神经网络(作为分类器)的原则方法,称为FP覆盖算法.本文将按照文献［1］中给出的构造FP覆盖算法的原则,深入地进行讨论,给出一种常用的覆盖算法,暂且称之为“交叉覆盖算法”.本算法在一定意义上解决了多年来一直未解决的(作为分类器)多层前向网络的设计问题.最后给出两个模拟的例子,并指出本算法可以用来解决“无穷样本的学习问题”(而无穷样本学习问题用其他学习算法是无法解决的),这充分说明本算法的有效性.为方便读者阅读,下面简单介绍文献［1］中所用到的一些内容(详细情况见文献［1］).
　　M-P神经元模型的几何意义简介.
　　若我们限定输入向量的长度相等,即输入向量是限定在n+1维空间的某个球面Sn上(其中心在原点,半径为R),那么这时(W*x-θ)>0(其中W是权向量,θ是阈值),就表示球面上落在由超平面P(其方程为:(W*x-θ)＝0)所分割的正半空间的部分,这个部分恰好是球面上的某个“球形领域”.若取W与x等长,则这个“球形领域”的中心恰好是W,其半径为r(θ)(r(θ)＝R(cos-1(θ/R2)),如图1所示.


（a）超平面P与超球面相交，形成“球形领域”的示意图（b）从D→Sn变换的示意图
图1


　　若我们令,且取神经元的激励函数为σ′(W*x-θ),则一个神经元的激励函数正好是它所代表的球面上“球形领域”的特征函数,这样,我们就将神经元与球面上的球形领域对应起来.利用神经元的这种几何意义,我们就能非常直观地进行神经网络的各种研究.
　　由上面给出的神经元的几何意义得知,构造一个网络,使对给定的样本集能进行符合要求的分类,等价于求出一组领域,对给定样本集K中的点,能按分类的要求用领域覆盖将它们分隔开来.这样,我们就将神经网络的最优设计问题转化成某种求最优覆盖的问题.
　　当给定的输入向量的长度不相等时,可用下面给出的方法,将它变换成长度相等的情况.
　　设输入的定义域为n维空间中的有界集合D,令Sn是n+1维空间中的n维的超球面,作变换
　　　　　　　　
其中d≥max{｜x｜｜x∈D}.
　　这个变换可从几何上直观地理解为:将D看成是位于n+1维空间中过原点的一个n维超平面上,而且D位于Sn的内部,则变换T就是将D上的点垂直投射到Sn的上半球面上.这种变换显然是一一对应的.如上面所述,这时每一个神经元(W,θ)就是在超球面Sn上,以W为中心,以r(θ)为半径的一个“球形领域”的特征函数(其中r(θ)＝r(cos-1(θ/R2))).
1　多层前向神经网络的交叉覆盖设计算法
1.1 问题的提出
　　设给定一输入集K＝{x1,x2,...,xk}(K是n维欧氏空间的点集),设K分为s个子集K1＝{x1,x2,...,xm(1)},...,Ks＝{xm(s-1)+1,xm(s-1)+2,...,xk}.现求作一个三层网络N,满足:通过这个网络后,属于Ki的点的输出均为“yi”,其中yi＝(0,...,1,0,...,0)(即其第i个分量为1,其余分量为0的向量).i＝1,2,...,s.
　　下面,为讨论方便,令s＝2,且令y1＝1,y2＝-1.
1.2 交叉覆盖算法
　　由文献［1］知,用三层神经网络构造分类器,等价于求出一组领域,这组领域能将不同类的点分隔开来.下面,我们给出一个称为“交叉覆盖法”的算法.其主要思路是:先求一个领域C1,它只覆盖K1中的点,而不覆盖K2中的点,然后将被C1覆盖的点删去.对余下的点求另一领域C2,它只覆盖K2的点,而不覆盖K1的点,然后将被C2覆盖的点删去,...,如此交叉进行覆盖,直到K1(或K2)的点全部被删除为止.
　　在上面求Ci时,当然希望它覆盖的点越多越好,因为这样就能用较少的领域完成覆盖的任务,也就是,说所得到的网络的元件个数就越少.下面给出一个求Ci的方法(此法未必能求到最优的领域Ci,但一般可得到较优的领域).其求法的要点是:用“求重心＋求领域”和“平移＋求领域”交互进行,求得较好的领域Ci.
　　算法1. 求交叉覆盖的步骤
　　首先将K1,K2的点映射到球面Sn上(Sn是n+1维空间中,中心在原点,半径＝R的n维球面,取其半径R＞max|xi|)仍记为K1,K2.
　　第1步:作一覆盖C(i)(开始时i＝1),它只覆盖住K1的点,被C(i)覆盖的K1中的子集为K1i,
　　令K2←K1/K1i,K1←K2,若K1或K2为空集,停止.否则,i＝i+1,返回第1步.
　　由算法1求到一个覆盖集合,记为C＝{C1,C2,...,Cp}.
　　网络设计:
　　第1元件层,取p个元件A1,A2,...,Ap,其中Ai为对应于Ci的神经元,i＝1,2,...,p.其功能函数暂设为特征函数.
　　第2层取一个p输入的神经元B,设其权阈值为(u,a),ui和a可由下面的方法求得(不妨设最后K1为空集,而K2不为空集,以及K1对应的输出为1,K2对应的输出为-1):
　　　　　　　　　　　　-a＜0　(剩下的K2对应的方程),
　　　　　　　　　　　up-a＞0　(第p个覆盖中各点满足的方程),
　　　　　　　　　up-1+up-a＜0
　　　　　　　或 up-1 ...-a＜0　(第p-1个覆盖中的各点满足的方程),
　　u1+b2u2+b3u3+...+bpup-a＞0　(第1个覆盖中的各点满足的方程),
其中bi取1或0,由各点的具体情况而定.不管bi取何值,上式一定有解.可取a＝1,up＝2,up-1＝-2,up-2＝4,一般
　　这样的网络就构成分类器,将K分为K1和K2(即对应于K1(K2)中的点,其输出＝1(-1)).
　　注:按上述方法求到的输出层神经元的权系数,将随样本个数的增加,呈指数增加.为避免这个问题,我们可以增加一个隐层,则可使输出层的权系数至多只按样本数呈线性增加.
　　算法2. 求覆盖C(i)的步骤
　　第1步:若K1或K2有一个是空集,则停止;否则(不妨设K1≠)任取ai(开始时,j＝1,i＝1)属于K1.
　　第2步:求以ai为中心的领域C(ai).令C(ai)∩K1＝Di,i＝1,2,...,D0＝,
　　［C(ai)对应的权和阈值(Wi＝(wij),θ＝(θi)),可按下面的公式求得:
令　　　　　　　　　　　　
　　　　　　　　　　　　
　　　　　　　　　　　　　　　　　θi＝d(i),
　　　　　　　　　　　　　　　W＝(ai),θ＝(θi)］.
　　第3步(求重心):若Di-1是Di的真子集,则求Di重心a-,令ai+1← a-,i←i+1,返回第2步.否则,进入第4步.
　　第4步(平移):求ai的平移点a′,令 ai+1＝a′(a′的求法见算法3),并求对应的领域C(ai+1)(求领域C时,需将ai-1投射到球面上),得Di+1.
　　若Di是Di+1的真子集,则求Di+1重心a-,令ai+1←a-,i←i+1,返回第2步.
　　否则,令Cj＝C(ai),这样我们就求到一个覆盖Cj.
　　然后,将被Cj覆盖的点删去,即令 K1j＝Cj∩K1,K2←K1/K1j,K1←K2,j←j+1,回到算法1的第1步,求另一个覆盖.最后得到一组领域{C1,C2,...,Cp}.
　　算法3. 求平移算法(求a的平移点a′)
　　设a∈K1,,其中d(a,x)表示a与x的距离.
　　第1步:若|B|＝k＞n,则取a′＝a.若成功,则停止.
　　否则,求a到P(B)(其中P(B)是由B构成的线性流型)的垂足b,令P(k)＝P(B),再对每个x∈K2/P(k),求d(x):
　　　　　　　　　　　　
其中c是P(k)中的任一点.
　　若存在x:〈a,c-x〉＝0,则令x＝ck+1,取a′＝a,令P(k+1)＝P(k)∪{ck+1}.进入第2步.
　　否则,令
　　　　　　　　　　　　　　　　　　　　　　(1)
令　　　　　　　　　　　　　　
其中R是球面Sn的半径.即将(a-db)的向量投影到Sn球面上.再取ck+1＝x*.
　　第2步:令P(k+1)＝P(k)∪{ck+1}(这里,我们为简单起见,用P(k)∪{ck+1}表示由P(k)和ck+1构成的线性流型).
　　若k+1＞n,则a′为所求.若成功,则停止.
　　否则,求a′到P(k+1)(开始时,k＝|B|)的投影bk+1,令b＝bk+1,a＝a′,k←k+1,返回第1步.
　　求投影算法.
　　设P(k)＝{c1,c2,...,ck}(P(k)是算法3中所定义的P(k)),a不属于由P(k)构成的流型(仍记为P(k)),求a到P(k)的投影.
　　我们可用先求归一化的正交基,然后再用求投影的方法来求投影.
　　求P(k)的正交归一化基的方法为
　　　　　　　　P(k)＝{c1,c2,...,ck},di＝ci-c1, i＝2,...,k,
令　　
于是,求a到P(k)的投影为
　　　　　　　　　　
　　这样,当P(k-1)的正交基已求得,再求P(k)的正交归一化基时,只要再求ek,连同e1,...,ek-1,就构成P(k)的正交归一化的基.
　　下面我们要证明的是,按算法3,将a平移后得到a′点,若以a′为中心,作只覆盖K1点的领域,则此领域的半径比以a为中心,只覆盖K1点的领域的半径大.这样就证明了,通过平移,有可能求到覆盖更多K1点的领域.
　　命题1. 设a,P(k)是算法3中对应的符号,则有a到P(k)中各点的距离相等.
　　证明:当k≤|B|时,由B的定义知,命题结论成立,现用归纳法加以证明.
　　若存在x:〈a,c-x〉＝0,由〈a,c〉＝〈a,x〉,直接得d(a,c)＝d(a,x);若求到x*,取ck+1＝x*,由d(x*)＝,得〈a-d(x*)b,c〉＝〈a-d(x*)b,x*〉,故有d(a′,c)>＝d(a′,x*)＝d(a′,ck+1).　　□
　　命题2. 设a′是a按算法3求到的平移点,则C(a)C(a′),且C(a′)只覆盖K1的点.
　　证明:作C(a′)(C(a))是以a′(a)为中心,以a′(a)到c(c是P(k)中的任一点)的距离为半径的领域,于是C(a′)(C(a))的方程为〈a′,x-c〉＞0(〈a,x-c〉＞0).下面证明,若x满足〈a,x-c〉＞0,则x一定也满足〈a′,x-c〉＞0.
　　由于当x落在C(a)内时,有d(x)＝,于是〈a′,x-c〉＝〈a-d(x*)b,x-c〉＝〈a,c-x〉-d(x*)〈b,c-x〉,由〈a,c-x〉＞0及d(x)＜0得,〈b,c-x〉＜0,故有〈a′,c-x〉＞0,即x也属于C(a′),得C(a)C(a′).
　　另外,由d(x*)的定义易得,C(a′)(C(a))只覆盖K1的点.　□
　　由命题1、2知,按算法3求平移点所得到的对应的领域,覆盖K1点的范围将会越来越大,这正是我们所要达到的目的.
　　注:我们这里给出的只是求覆盖领域的方法之一.此方法未必能保证每次求到的领域C(a)覆盖K1的点达到最多,故算法还有改进的余地.
2　模拟结果
　　本节给出两个很有代表性的例子,由这些例子就可看出本文所给出的方法的潜力.
　　例1:平面上双螺旋线的识别问题(如图2所示).

曲线为双螺旋线，○及△表示两类训练样本点
图2　平面双螺旋分类问题
　　设K1是在极坐标系中曲线r＝θ上的子集,K2是在极坐标系中曲线r＝－θ上的子集,π/2≤θ≤6π.
　　K1(K2)上各有77点,其θ值为θ＝iπ/2,i＝1,...,12,以及π/2到π,取二等分点,π到3π/2取三等分点,一般iπ/2到(i+1)π/2区间取i+1等分点.
　　求一个三层前向神经网络,将K1,K2分开.这个例子是神经网络学习中有名的难学习的问题之一.
　　在文献［2］中,Raum等人用BP算法求解双螺旋线问题,结果失败了.在文献［3］中,Chen等人提出“生成-收缩”法,来求解双螺旋线学习问题,经过3 000次的迭代,得到一个解,此解识别的正确率只有89.6%.在文献［4］中,Fahlman等人用“级联式”网络结构才勉强解决了双螺旋线学习问题,所得的网络要用几十个神经元.可见此问题的难度.下面我们用交叉覆盖算法求解此问题,得到了非常令人满意的结果.
　　解:用交叉覆盖算法求解此问题,得网络第1层共有10个神经元(如图3所示,其中椭圆是各领域在二维平面上的投影).第2层仅一个神经元,整个网络共用11个神经元.网络对样本的分类正确率为100%.


　　(a)训练数据为双螺旋上156个样本点　　(b)训练数据为20 000个数据点
　　图中黑色表示网络所划分的第1类样本的覆盖区域,白色表示第2类样本的覆盖区域,○及△表示两类训练样本点
　　图3　采用逐次覆盖法对平面双螺旋分类问题的求解结果


　　然后我们在曲线r＝θ(r＝－θ)上随机各取1万个点作为测试样本,输入所得到的网络进行识别,正确率达到98.245%.另外,我们又随机地在K1,K2上各取1万个点作为样本点,然后进行学习,仍得到10个神经元(其在二维上的投影如图3(b)所示),这时不但其分类的正确率为100%,而且我们在两类中各随机取1万个点进行识别,其识别正确率也达到99.995%.
　　另外,我们还进行了平面三螺旋线和三维空间三螺旋线的学习问题,都得到了非常令人满意的结果,见表1.
　　　　表1　用交叉覆盖算法学习的情况表

问题训练样本
(样本数)学习时间覆盖数测试样本
(样本数)识别率(%)
平面双螺旋线1 (156)
2(20 000)＜1ms
5.16s10
10(20 000)
(20 000)98.245
99.995
平面三螺旋线1 (234)
2(30 000)0.06s
14.61s24
26(30 000)
(30 000)91.11
99.067
空间三螺旋线1 (183)
2(30 000)0.07s
19.34s28
37(30 000)
(30 000)96.293
99.653


　　例2:求三维空间上两根螺旋线的识别问题.
　　设在柱坐标系中,K1＝{(θ,r,z)|z＝θ,r＝1,0≤θ≤4π},K2＝{(θ,r,z)|z＝θ＋π,r＝1,0≤θ≤4π},求一个三层前向神经网络将K1,K2分开.
　　注:例2是一个无穷样本的识别问题,用其他方法(如BP算法)是无法解决的.用本文提供的方法,可以比较圆满地解决这个学习问题.
　　解:用交叉覆盖设计法(要求覆盖住K1,K2曲线上的所有点)求得的网络,第1层10个元件,第2层1个元件.
　　我们随机地在曲线K1和K2上共取30 000个点,当作测试样本输入所得的网络进行识别,结果全部识别正确.
　　上面的两个例子可以充分说明本文所给的设计方法的有效性.此两例若用其他算法(如各种改进过的BP算法)进行设计将是相当困难的. 
3　结束语
　　本文利用M-P神经元模型的几何意义得出一个领域覆盖的设计算法.这个算法在一定意义上考虑到网络的结构优化问题(指网络的规模最小),并且方法切实可行,从而解决了多年来一直未能很好地得到解决的多层前向网络的设计问题.本文给出的几个模拟例子也充分说明了本方法的潜力.
　　另外,我们这里给出的覆盖设计算法只是领域覆盖设计算法中的一个特例,任何一个求最小(次小)覆盖算法与本文提出的设计原则相结合,都可得出一个新的设计算法.这就给研究网络设计问题开辟了一个新途径.
　　致谢　清华大学的李凌同学为本文的表1提供了模拟例子,在此表示感谢.
　　本文研究得到国家自然科学基金和国家863高科技项目基金资助.作者张铃,1937年生,教授,主要研究领域为人工智能理论,人工神经网络理论.张钹,1935年生,教授,博士生导师,中国科学院院士,主要研究领域为人工智能理论及应用,计算机应用技术.殷海风,1970年生,硕士,主要研究领域为人工神经网络理论及应用.
　　本文通讯联系人:张铃,合肥230039,安徽大学人工智能研究所
　　作者单位：[张　铃（清华大学智能技术与系统国家重点实验室　北京　100084）；殷海风(安徽大学人工智能研究所　合肥　230039)]　张　钹(清华大学计算机科学与技术系　北京　100084、清华大学智能技术与系统国家重点实验室　北京　100084)
　　E-mail: zling@mars.ahu.edu.cn
参考文献
　1　张铃,张钹.M-P神经元模型的几何意义及其应用.软件学报,1998,9(5):334～338
　　(Zhang Ling, Zhang Bo. A geometrical representation of M-P neural model and its applications. Journal of Software, 1998,9(5):334～338)
2　Baum E B, Lang K J. Constracting hidden units using examples and queries.In: Lippman R P et al eds. Neural Information Processing. San Mateo, CA: Morgan Kaufmann Publishers, Inc., 1991. 904～910
　3　Chen Q C et al. Generating-shrinking algorithm for learning arbitrary classification. Neural Networks, 1994,5(7):1477～1489
　4　Fahlman S E, Lebiere C. The cascade-correlation learning archtecture. In: Tourdtzhy D S ed. Advances in Neural Information-processing System. San Mateo, CA: Morgan Kaufmann Publishers, Inc., 1990. 524～532
1998-01-16收到原稿 
1998-08-24收到修改稿
