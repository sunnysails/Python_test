计算机研究与发展
JOURNAL OF COMPUTER RESEARCH AND DEVELOPMENT
1999年 第36卷 第5期 Vol.36 No.5 1999



一种短语结构规则的自动获取方法
朱靖波　张杰　姚天顺
摘　要　文中提出一种新的知识获取方法，即从完全没有任何标注的生语料库中，采用NA假设自动构造带标训练数据，利用基于多特征的相似评估技术自动获取名词短语结构规则.该方法具有两个特点：① 由于从没有任何标注的生语料库中自动获取带标训练数据，促使带标数据规模可以很大，且容易构造不同领域的带标语料库；② 所获取的短语结构规则具有概率属性，可用于分类检索等应用中的名词短语抽取.为论证方法有效性，采用美国Berlitz公司的汽车配件真实语料进行测试，前50个名词短语结构规则的准确率高达80%.
关键词　名词短语结构规则，距离函数，基于多特征的相似评估
中图法分类号　TP391
A NEW APPROACH TO PHRASE STRUCTURE RULE ACQUISITION
ZHU Jing-Bo, ZHANG Yue-Jie, and YAO Tian-Shun
(Institute of Computer Science, School of Information Science and Engineering, Northeastern University, Shenyang　110006)
Abstract　Here presented is a new approach to NP phrase structure rule acquisition based on multi-feature similarity estimation from corpora without bracketed and nonterminal labels. By computing the distance between a rule and all feature rules based on their local contextual information, the system could sort all rules by their distances. The smaller the distance, the larger the similarity. Experiments using Berlitz corpus show that the approach presented achieves a relatively high accuracy: 80% in the first 50 rules. This result demonstrates that training data acquisition based on NA assumption is effective for rule acquisition and parsing.
Key words　noun phrase structure rule, distance function, multi-feature-based similarity estimation
1　引　　言
　　目前许多自然语言处理系统采用基于文法的句子分析技术，但是手工构造文法的难度大，十分复杂.国内外学者提出了许多基于语料库统计的文法自动获取方法.这些自动获取方法可以根据它们使用的语料库特点来分类，例如训练语料库中是否具有短语边界标注，或者非终结符号标注等等.国外有一些具有边界全标注和非终结符号标记的英文分析语料库，很多研究人员利用这些语料库来构造概率文法［1～4］.同时从具有非终结符标注的语料库统计文法的概率，应用于评估句子的分析结果的概率.
　　实际上目前很多基于统计的分析技术取得了很好的实验结果，很大程度依赖于语料库构造的代价.为了减轻人工标注语料库的瓶颈问题，如何从更少标注代价的语料库中获取更多、更深层次的知识的获取技术的研究越来越有意义.例如利用没有非终结符标注或者部分标注的语料库进行统计分析.国外有很多语料库只有边界标注，没有非终结符标注，如EDR语料库［5］，ATIS口语语料库［6］等等.Baker［7］很早就利用Inside-Outside算法，从没有非终结符标注的语料库中获取概率上下文无关文法用于语音识别［8，9］.但是获取的概率文法严格限制为CNF（Chomsky normal-form），训练语料库规模不大，获取概率文法的计算复杂度特别大.Thanaruk Theeramunkong和Manabu Okumura［10］从没有非终结符标注，具有边界标注的语料库中，利用聚类分析技术获取概率上下文有关文法，进行句法分析.实验结果表明对于短句子取得了很好的效果.
　　针对上述一些问题，文中提出了一种新的知识获取方法，从完全没有任何标注的生语料库中，采用NA假设自动构造带标训练数据，利用基于多特征的相似评估技术自动获取名词短语结构规则.这种方法具有两个特点，首先由于带标训练数据是从没有任何标注的生语料库中自动获取的，这样促使带标训练数据的规模可以很大，并且很容易构造不同领域的带标语料库.其次，该方法获取的短语结构规则具有概率属性，同时利用局部上下文（前后两个词性）计算规则的概率分布.因此短语结构规则及其概率分布可以用于从文本中抽取名词短语用于分类检索应用等等.为了论证该方法的有效性，本文采用美国Berlitz公司的汽车配件真实语料进行测试，最后给出实验结果.
2　距离函数
　　本节将讨论一些用于测试不同概率分布相似程度的函数的计算特性，我们称这些函数为距离函数.通过距离函数计算不同概率分布之间的距离，距离越小，相似程度越大.本节主要讨论两种距离函数：基于Kullback-Leibler［11］距离的距离函数和基于几何形式的距离函数.本文的实验结果将验证各种距离函数的有效性.
2.1　概率分布评估
　　对象o的条件概率分布Po使用最大似然估计方法（maximum likelihood estimate，MLE）来计算.MLE方法使用训练数据来评估下面的条件概率Po=PMLE(c|o)：
　　　　　　　　　　　　　　　(1)
　　其中R(o,c)表示对象o在局部上下文c条件下在训练语料中出现的次数.同理R(o)表示对象o在训练语料中出现的次数.我们设定当R(o,c)=0，则PMLE(c|o)=0.也就是说，由于受到样本语料的规模限制，一旦出现某一数据对(x,y)没有出现在训练样本语料中，我们可能得出该数据对的条件概率PMLE(c|o)为0.实验发现，许多数据对即使出现在训练样本语料中，计算得出的结果也是属于低概率事件，这就是我们稀疏数据问题.严重的稀疏数据问题会导致这种评估方式成为没有太多价值.
　　为了解决稀疏数据问题，后来许多人提出了一些MLE的改进方法.基本思想将MLE作为最初的评估，然后将数据对的条件概率之和小于1，留出一部分概率赋给未出现在样本语料中的可能数据对.这个技术我们称之为平滑（smoothing）技术.
　　Jelinek和Mercer［12］提出了著名的内插法平滑技术.我们采用简化的内插法平滑公式：
　　　　　　　　　　(2)
　　其中R(o,c)表示(o,c)在训练语料中出现的次数，R(o)表示对象o在训练语料中出现的次数.|CT|表示局部上下文的数目.本文考虑的局部上下文为对象的前一个词的词性和后一个词的词性，因此可以得出：|CT|=13种词性×13种词性=169种局部上下文.在本文的实验中，设置插值参数λ为0.99，取得了很好结果.
2.2　基于Kullback-Leibler距离的距离函数
　　首先定义o1和o2为两个不同的对象，CT为局部上下文，c∈CT表示某一具体局部上下文.Po1和Po2分别表示对象o1和o2的概率分布.Kullback-Leibler距离公式定义如下：
　　　　　　　　(3)
　　我们可以利用D(Po1‖Po2)+D(Po2‖Po1)来计算两个不同概率分布Po1和Po2的距离，距离函数ξ(Po1,Po2)如下：
　　　　(4)
2.3　基于几何形式的距离函数
　　如果我们把(Po1, Po2,…，Pon)看作一个向量空间，就可以通过几何方式计算不同概率分布的距离，从而评估它们的相似程度.
　　几何形式的距离函数有两种形式：
　　(1) L1形式，计算公式如下：
　　　　　　　　　　(5)
　　(2) L2形式，计算公式如下：
　　　(6)
　　很明显，当且仅当对于所有c∈CT，Po1=Po2，L1(Po1,Po2)=L2(Po1,Po2)=0.
3　训练数据的自动构造
3.1　Nonambiguity-Ambiguity假设
　　为了方便描述这个Nonambiguity-Ambiguity假设，下面简称NA假设.为了自动抽取带有词性标注的训练数据，本文定义语料库中具有如下特征之一的词汇为无歧义语言现象，反之为具有歧义的语言现象.4个特征描述如下：
　　(1) 词典中只具有单一词性的词汇，如英文代词词汇“we”；
　　(2) 可以通过形态分析确定唯一词性的词汇，如英文动词词汇“bought”；
　　(3) 可以通过前缀和后缀分析确定唯一词性的词汇，如英文形容词词汇“well-founded”；
　　(4) 非英文词汇，如数字、标点符号等.
　　定义1.Ω为语言现象集合，ΩA为具有歧义的语言现象集合，ΩN为无歧义的语言现象集合.很明显：ΩA∪ΩN =Ω.
　　NA假设：利用ΩN构造带标训练语料库，训练N-Gram概率模型的参数，完成对ΩA的消歧处理是可行的.
　　例如针对两个英文词汇“I”和“report”，我们知道，英文词汇“I”只有一种词性代词(R)，所以词汇“I”∈ΩN，但是英文词汇“report”具有两种词性：名词(N)和动词(V)，所以词汇“report”∈ΩA.
　　根据NA假设，我们可以将单个词性和通过简单处理可以唯一确定词性的语言现象构成带标训练语料，训练N元语法模型的参数.
3.2　带标训练数据的自动构造过程
　　我们采用的源语料是美国Berlitz公司的汽车配件真实语料，未经过任何词性人工标注.为了从源语料库中抽取出训练数据，我们构造了两个词库：基本词库：具有大约4万多基本词汇，每个基本词汇具有词性全集和专业词库：具有大约两万多汽车配件专业词汇，每个专业词汇具有词性全集.英文词汇词性定义［13］如下：
表1　英文词汇词性

名词N动词V形容词A
副词D介词P助动词X
连词C感叹词E代词R
数词M冠词Z标点符号W
其他类型O　　　　


　　为了实现对英文词汇的形态分析，我们构造了一个基于规则的形态分析器.训练数据的自动构造过程分为4个步骤：
　　步骤1. 对非英文词汇的识别，包括数字类型、标点符号类型和其它类型；
　　步骤2. 直接查词库过程，将词库中所有词性作为标注结果，查不到标注为NULL；
　　步骤3. 利用通用缩略语和不规则动词表，前缀和后缀规则对英文词汇进行形态分析；
　　步骤4. 带标训练数据的生成.
　　下面以一个句子来说明处理过程：
　　They reported the enemy to be 10 miles away.
　　步骤1识别结果：
　　They reported the enemy to be 10(M) miles away.(W)
　　步骤2识别结果：
　　They(R) reported(NULL) the(Z) enemy(N) to(P) be(V,X) 10(M) miles(NULL) away(D).(W)
　　步骤3识别结果：
　　They(R) reported(V) the(Z) enemy(N) to(P) be(V,X) 10(M) miles(N) away(D).(W)
　　步骤4识别结果： 
表2　训练数据自动抽取结果

序号词汇训练数据带标训练数据
1They reported the enemy to　　R V Z N P
2be　　NULL
310 miles away.　　M N D W


3.3　带标训练数据的自动抽取结果
　　我们采用的源语料是美国Berlitz公司的汽车配件真实语料，覆盖了汽车配件的使用和维修内容，没有任何标注，包含大约4万个英文句子.带标数据的抽取处理程序在P266的微机，PWindows98环境下，处理平均速度大约为15句/秒.带标训练数据抽取结果统计如下： 
表3　带标训练数据自动抽取结果统计

源语料库规模大小Ω训练语料库规模大小ΩN具有歧义的数据规模大小ΩA
674116402722271394


　　为了验证基于NA假设的训练数据自动抽取方法有效性，我们曾经将自动获取的带标训练语料库用于词性自动标注应用中，对两万词次关于汽车配件的真实语料进行开放性测试，准确率达到93%以上.下文将利用自动抽取的带标训练数据进行训练名词短语结构规则的自动获取模型的参数. 
4　名词短语结构规则的自动获取过程
　　最近几年，国外有许多学者利用带短语边界和非终结符标注的语料库进行获取上下文无关文法；还有一些学者利用只有短语边界标注，没有非终结符标注的语料库进行获取概率文法.本文提出的概率文法获取方法采用的语料库没有短语边界、非终结符和词性标注，采用基于多特征的相似度评估技术，进行自动获取名词短语结构规则.实际上，本文获取的名词短语结构规则是具有概率属性，同时利用了局部上下文信息（前后两个词性）构造了名词短语结构规则的概率分布.国外有些文献讨论了局部上下文的有效性问题［10］.本文提出的文法自动获取过程主要分为5个步骤：
　　Step1.首先构造名词短语结构特征产生式，同时计算它们的概率分布；
　　Step2.构造名词短语结构产生式候选集合，设置产生式的右边最大长度为5；
　　Step3.计算候选集合中所有产生式的概率分布；
　　Step4.计算候选集合中所有产生式的概率分布与所有特征产生式的概率分布的距离；
　　Step5.根据平均距离对候选集合中所有产生式进行从小到大进行排序.
4.1　特征的选取和构造
　　名词短语结构的特征很多，本文的实验中主要选取了其中3个特征F：① 形容词加名词可以组成名词短语；② 数词加名词可以组成名词短语；③ 冠词加名词可以组成名词短语.我们可以采用产生式形式来描述3个特征F，即：① F1：NPA+N；② F2：NP M+N；③ F3：NPZ+N.根据第2.1节论述的公式(2)分别计算3个特征的概率分布，即：
　　(1) 构造Ω(F1)=(P(c1|F1),P(c2|F1),… …,P(cn|F1))，其中ci∈CT；
　　(2) 构造Ω(F2)=(P(c1|F2),P(c2|F2),… …,P(cn|F2))，其中ci∈CT；
　　(3) 构造Ω(F3)=(P(c1|F3),P(c2|F3),… …,P(cn|F3))，其中ci∈CT；
　　最后构造特征产生式的概率分布矩阵Ω(F)=(Ω(F1), Ω(F2), Ω(F3)).
4.2　候选集合的构造
　　首先我们假设任何短语结构都可以组成名词短语，本文实验中设置了名词短语的最大长度为5个词汇.根据这个假设，我们很容易构造名词短语结构规则的候选集合φ，构造过程分为5步操作：
　　(1) 任取1个词性E，构造产生式Pro：NPE，增加Pro∈φ； 
　　(2) 任取2个词性E1和E2，构造产生式Pro：NPE1 E2，增加Pro∈φ；
　　(3) 任取3个词性E1，E2和E3，构造产生式Pro：NPE1 E2 E3，增加Pro∈φ； 
　　(4) 任取4个词性E1，E2，E3和E4，构造产生式Pro：NPE1 E2 E3 E4，增加Pro∈φ；
　　(5) 任取5个词性E1，E2，E3，E4和E5，构造产生式Pro：NPE1 E2 E3 E4 E5，增加Pro∈φ；
　　从理论上说，根据这种方法生成的名词短语结构的数目为402233（计算公式为：135+134+133+132+13=402233）.实际上在这庞大数目的产生式集合中大量是不合法的产生式.为了减少不必要的运算量，实验中采用了下列两条原则进行初步筛选.筛选原则如下：
　　原则1.该产生式结构在语料库中至少出现一次；
　　原则2.标点符号、连词、介词、助动词、感叹词、副词不能在一个名词短语本身第一个和最后一个词汇的位置出现.
　　我们把经过初步筛选的产生式作为候选集合，在本文的实验中，候选集合中产生式的数目降低到432个.然后根据第2.1节论述的公式(2)计算候选集合中所有产生式的概率分布.计算方法如下：
　　任取一个产生式Proi∈Φ，构造Ω(Proi)=(P(c1|Proi),…,P(cn|Proi))，其中ci∈CT.
4.3　基于多特征的相似性评估
　　我们采用第2节介绍的距离函数来评估候选集合中产生式与特征产生式的概率分布的相似度，距离越小，相似度越大.本文方法中利用与所有特征产生式概率分布之间的平均距离来评估相似度.根据第2节介绍的3个距离函数式(4)～(6)，可以推导出3个平均距离DIS(Pro,F)的计算公式.
　　采用ξ距离函数式(4)，计算公式1：
　　　　　　　　　　　(7)
采用L1距离函数式(5)，计算公式2：
　　　　　　　　　　(8)
采用L2距离函数式(6)，计算公式3：
　　　　　　　　　　　(9)
其中，候选产生式Pro∈Φ，特征产生式Fi∈F，本文实验中采用了3个特征产生式，即：n=3.
5　实验结果
　　为了验证该方法有效性，我们作了如下实验.源语料库是美国Berlitz公司的汽车配件真实语料，覆盖了汽车配件的使用和维修内容，没有任何关于短语边界、非终结符和词性的标注.在第3节中详细论述带标训练数据的自动抽取过程，自动构造的训练语料库规模大小为402722词次.该实验完成分别利用3个平均距离计算公式(7)～(9)自动获取名词短语结构产生式规则.下面图中描述利用不同距离计算公式计算的平均距离与自动生成的产生式数目之间的关系.
