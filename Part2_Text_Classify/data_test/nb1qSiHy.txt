软件学报
JOURNAL OF SOFTWARE
1999年 第6期 第10卷 Vol.10 No.6 1999



基于神经网络的纹理和灰度信息融合方法*
刘宁宁　田　捷　胡志刚　诸葛婴
　　摘要　文章从信息融合的角度出发,利用神经网络的方法将纹理和灰度信息有机地融合起来,设计并实现了一种基于子区域的区域增长分割算法.并将该方法应用到医学图像的分割问题中，取得了较好的效果.实验表明,该方法针对一类图像能够得到较好的结果.
　　关键词　图像分割,信息融合,神经网络,医学图像.
　　中图法分类号　TP391
　
An Information Integration Method of Texture and 
Gray Based on Neural Network
LIU Ning-ning TIAN Jie HU Zhi-gang ZHU-GE Ying
(Institute of Automation The Chinese Academy of Sciences Beijing 100080)
　　Abstract A segmentation method in which texture and gray variation information is integrated by means of function-linked neural network is proposed in this paper. Based on this method, a region-based region growing algorithm is designed and applied to medical image segmentation. The experimental results show that this method can produce good segmentation result when applied to certain images.
　　Key words Image segmentation, information integration, neural network, medical image.
　　图像分割是图像处理与分析中的一个经典问题,研究者针对各种不同的问题提出了许多解决办法.N.R.Pal 和S.K.Pal在文献［1］中对图像分割的算法做了较好的概述.但是，图像分割问题至今尚未建立一个普遍适用的理论和方法.图像分割在医学图像的应用中具有特殊的意义,譬如定量分析器官以及病变区域的几何尺寸、三维重建的实现等,均需要图像分割技术的保证.我们从融合多种信息的观点出发,提出了融合灰度和纹理信息的解决方法.该方法利用特征扩展技术实现对纹理、灰度变化特征的扩展,进而借助神经网络实现信息的融合.我们在此基础上设计并实现了一种区域增长算法,在区域增长的过程中利用训练好的网络作为评判分类器,对候选子区域进行评判,最终得到分割区域.整个方法分为3个步骤:首先，由操作者指定分割对象区域,在对象区域中指定若干子区域并提取子区域的纹理和灰度信息,同时在预分割区域的附近指定非分割对象的若干子区域,提取子区域的纹理和灰度信息；第2步，评判网络的训练,在此过程中，首先对提取的信息进行扩展,然后利用神经网络学习分割对象子区域与非对象子区域的差别;第3步，采用将基于子区域的区域增长算法,在此过程中，训练好的网络作为候选子区域的评判分类器，最后针对边缘像素点进行必要的处理.实验证明,这种方法针对一类图像能够得到较好的结果.
1　方法描述
　　我们知道，人体的不同组织器官在CT或者MRI的图像中具有各自明显的纹理和灰度特征,如图1所示的人体腰部的MRI图像.鼠标指向的区域具有较丰富的纹理信息.如果我们在分割过程中能够有效地利用这些信息,或许可以得到较好的结果.我们在研究中发现,针对同一分割区域而言,其中不同空间位置的子区域所包含的灰度和纹理信息基本相同,这些子区域之间的灰度信息以及纹理信息的相对变化也比较一致.因此，分割区域的灰度、纹理变化信息可以作为刻画特定区域的特征.认识到这一点,我们提出了融合灰度和纹理信息的方法，该方法有机地融合了灰度和纹理信息的变化.在此基础上,我们设计并实现了基于子区域增长技术的分割方法,在实际应用中取得了较好的效果.

　　　　　
图1
　　我们可以将分割问题转化为一个两类别的分类问题,即分割对象作为对象类Oobject,其他任何非分割对象(如背景等信息)均作为一类,即非对象类.这样，对于任何一个子区域，我们仅需将其输入到分类器中进行类别的检测,凡是属于对象类Oobject的就标记为分割区域.在实现过程中，我们将分割问题转变为两个子过程,亦即目标确定过程和目标提取过程.目标的确定为分割区域的空间定位,这一任务由操作者完成,操作者在分割区域中提取分割区域的描述特征,然后再在此基础上进行目标区域的提取.这样不仅可以保证分割对象的正确性,而且也使分割结果更加可靠.
为叙述下文的需要,我们在此给出两个定义,然后根据定义给出描述同一区域中不同子区域的纹理和灰度信息变化的方法,并且利用欧氏距离刻画不同子区域的信息变化.
　　为了刻画区域中的灰度分布信息,我们定义了灰度分布矢量Ginf.
　　定义1. 灰度分布矢量Ginf,Ginf=［p(0),p(1),p(2),p(3),...,p(L-1)］T,其中L为指定区域中的最大灰度级,,N(i)表示该区域中灰度级为i的像素点数,M为指定区域中的所有像素点数.为了刻画不同区域中灰度信息的变化,定义ΔGinf=‖Ginf/p-Ginf/q‖作为刻画灰度信息变化的特征.采用欧式距离

其中Ginf/k表示第k个子区域.
　　如图1所示,在图中鼠标所指的欲分割区域内,操作者可以交互地选择属于该区域的若干子区域,进行统计后得到代表整个欲分割区域的平均灰度信息,然后计算各个子区域与平均灰度分布信息的距离变化,并且认为这些变化是属于分割区域的子区域所特有的灰度信息的变化.
　　我们在图1箭头所指的区域中选取10个3×3具有代表性的子区域,得到灰度矢量Ginf/k,k=1,2,...,10;然后由这10个子区域得到代表整个区域的平均灰度矢量,分别计算10个子区域的灰度矢量Ginf/k与的距离,得到灰度变化信息.
　　为了刻画区域的纹理信息,我们给出特定区域的纹理信息度量矩阵Tinf.我们知道,在图像处理中常采用纹理共生灰度矩阵来刻画区域的纹理信息［2,3］,但是单一采用某个方向的共生矩阵不能很好地描述区域的纹理状态.在本文中,我们定义了所谓综合纹理信息度量矩阵,实验结果表明,该定义较好地结合了区域各个方向上的纹理信息.
　　 定义2. 综合纹理度量矩阵Tinf,

其中

式中：N(i,j,d,0°)=#｛(x,y),(s,t)∈R×R,｜x-s｜=d & y-t=0,f(x,y)=i,f(s,t)=j｝,
　　　N(i,j,d,90°)=#｛(x,y),(s,t)∈R×R,x-s=0 &｜y-t｜=d,f(x,y)=i,f(s,t)=j｝,
　　　N(i,j,d,45°)=#｛(x,y),(s,t)∈R×R,x-s=d & y-t=d or x-s=-d & y-t=-d,f(x,y)=i,f(s,t)=j｝,
　　　N(i,j,d,135°)=#｛(x,y),(s,t)∈R×R,x-s=d & y-t=-d or x-s=-d & y-t=d,f(x,y)=i,f(s,t)=j｝.
其中#代表符合要求的像素对的对数.
　　综合纹理度量矩阵结合了4个方向的纹理信息,因此,它包含的纹理信息较为丰富.为了定量地刻画不同区域的纹理信息的变化关系,我们定义纹理信息变化如下:

在实验中,我们按上述方法同时计算得出10个子区域的纹理度量矩阵,然后计算得出平均纹理矩阵,以为分割区域的平均纹理信息矩阵,计算所有10个子区域的纹理度量矩阵Tinf/k与Tinf之间的距离,得到纹理变化信息ΔTinf/k,k=1,2,3,4,...,10.
　　这样,我们就得到了属于分割区域对象类别的10个样本的灰度、纹理变化信息,如图2及表1所示.这些变化信息刻画了分割区域的灰度以及纹理的变化特性.同样地,如图3所示,我们可以得到不属于分割对象类别的10个区域,分别计算这10个区域的灰度、纹理与分割区域平均灰度以及平均纹理的信息差,从而得到10个可以刻画非分割区域的灰度以及纹理信息变化的、属于非对象类别的样本.这样,我们就得到了20个已知类别属性的样本,如表1所示.

　　　　　　　　　
图2　　　　　　　　　　　　　图3
表1

样　　本所属类别样　　本所属类别
0.566 558, 2.494 438O0.608 581, 2.454 525
0.496 904, 2.211 083O0.608 581, 2.494 438
0.544 331, 2.211 083O0.566 558, 2.287 918
0.521 157, 2.287 918O0.566 558, 2.298 684
0.471 405, 2.211 083O0.576 558, 2.372 684
0.471 405, 2.165 854O0.568 558, 2.255 309
0.521 175, 2.298 648O0.587 945, 2.372 684
0.544 331, 2.298 684O0.569 558, 2.341 256
0.534 432, 2.241 321O0.587 945, 2.424 158
0.563 544, 2.233 321O0.608 581, 2.504 317


　　其中的特征对为灰度矢量距离以及综合纹理距离,亦即灰度信息和纹理信息变化,O表示分割对象,表示除分割对象以外的任何区域.在实际处理中，我们令O=1,=0.
　　我们对得到的样本进行学习,得到能够区别分割区域与非分割区域的评判分类器.在实验中我们发现，由于抽取的特征只有灰度距离特征和纹理距离特征,使用普通的BP网络由于特征数较少而达不到满意的结果.因此,我们采用了特征扩展法对得到的特征进行扩展［4］,然后对扩展的样本进行学习,从而得到了较好的结果.我们采用了如图4所示这种结构的网络.

图4
　　该网络分为3层:扩展层、乘法层和计算层.在扩展层,对输入的灰度信息变化和纹理信息变化两个特征进行扩展.我们在实验中采用如下函数进行扩展,p(x)=cos(k*arccos(x))以及q(y)=cos(k*arccos(y)),在乘法层对扩展的特征进行乘法运算,从而在计算层得到新的输入特征,即new-k=p(x)*q(x)=cos(k*arccos(x))*cos(k*arccos(y)).在本文的实验中,特征在扩展层扩展为20维,隐藏层为50个神经元,1个输出节点;学习率为0.8,阻尼因子为0.9.对上述20个样本进行训练,网络在训练到第4 366步时达到训练要求,此时的系统总误差为0.000 599.所用机器为Pentium133,64M内存，所用时间约为3min.,速度还是相当快的.网络训练的结果如表2所示.
表2

样　　本输出网络输出样　　本输出网络输出
0.566 558, 2.494 43810.994 4990.608 581, 2.454 52500.000 012
0.496 904, 2.211 08311.000 0000.608 581, 2.494 43800.000 002
0.544 331, 2.211 08310.986 1480.566 558, 2.287 91800.000 003
0.521 157, 2.287 91810.999 9840.566 558, 2.298 68400.001 915
0.471 405, 2.211 08310.999 2770.576 558, 2.372 68400.000 001
0.471 405, 2.165 85410.999 4680.568 558, 2.255 30900.000 000
0.521 175, 2.298 64810.998 8330.587 945, 2.372 68400.000 062
0.544 331, 2.298 68410.994 5740.569 558, 2.341 25600.000 000
0.534 432, 2.241 32110.999 4750.587 945, 2.424 15800.000 010
0.563 544, 2.233 32110.998 8650.608 581, 2.504 31700.000 006


2　基于子区域的区域增长算法
　　训练好的网络用作下一步基于子区域的增长算法中的分类器.对于新的候选子区域,我们计算其与分割区域的平均灰度以及平均纹理的信息变化,将该变化输入到网络进行评判,从而得到分割子区域.
2.1　区域增长算法
　　我们设计并实现了基于子区域的区域增长方法,该方法如下.首先按照上述方法对网络进行训练,完成第1阶段的任务;然后开始区域的提取过程,即由用户在预分割区域中指定一个起始区域R0,然后以R0为中心得到其最近邻的8个方向的子候选区域,如图3所示,分别得到9个候选子区域的灰度矢量和纹理度量矩阵,然后计算各个候选子区域与分割区域的平均灰度和纹理之间的灰度信息差和纹理信息差,将二者输入到分类器中进行分类,若网络输出为1,则将该区域标记为分割区域中的成员;若分类器输出为0,则该子区域为非分割区域的成员,将该子区域从候选集合中删除;若网络拒绝评判,则将该子区域放入后处理集合中进行后处理.重复判断过程,直到不再存在候选区域为止.
　　算法.
　　Step 1. 用户在预分割区域中指定起始子区域R0,得到R0的灰度矢量Ginf/R0和纹理度量矩阵Tinf/R0.对初始区域进行评判,若初始区域不属于分割对象区域,则退出处理;否则继续.
　　Step 2. 建立初始区域R0的8个相邻子区域(如图5所示),并用这8个子区域初始化候选子区域集合C={候选子区域}.
　　Step 3. 如果候选子区域C不为空,则从C中任选一个候选子区域R,计算R的灰度矢量Ginf/R以及纹理度量矩阵Tinf/R.
　　Step 4. 计算候选子区域和分割区域平均灰度和平均纹理之间的灰度矢量距离和纹理度量矩阵的距离如下:

　　Step 5.将ΔGinf和ΔTinf输入到评判网络，判定该子区域是否为割对象，若是候选子区域为分割区域的一部分；然后构造该子区域的8个相邻子区域，并且将新的候选子区域并入候选集合C(集合中已存在的候选子区域不再并入)，返回Step 3.
　　Step 6.如果网络评判结果为否，则删除该候选子区域，返回Step 3.
　　Step 7.如果网络拒绝评判，则将该子区域放入后处理集合P中进行后处理.

图5
2.2　后处理
　　针对增长过程中得到的后处理集合P,其中的子区域中也许既包含了属于分割区域的像素点,同时也包含了不属于分割区域的像素点,因此,必须对这些区域进行特殊处理.在这些子区域中,我们采用了简单的边缘像素检测方法,利用区域的边缘处灰度的不连续性的特点,对该区域进行微分处理,以达到边缘检测的目的,将边缘内部的点标记为分割区域的像素点.在我们的实现中仅考虑了简单的一阶差分梯度算子
｜f(i,j)｜［（Δxf（i,j))2+(Δyf（i,j))2］1/2=［(f(i,j)-f(i,j+1))2+(f(i,j)-f(i+1,j))2］1/2.
对于得到的梯度较大的像素点标记为边缘点.
3　实验结果
　　我们在实验中选用了MRI图像数据,按上述方法进行了实验.实验平台为Pentium133,64M 内存.所用的网络评判器结构如第1节所述.实验结果如图6所示.

　　　　　　　　　　　
起始子区域　　　　　　增长中的区域　　　　分割结果区域
图6 实验结果
4　结 论
　　本文借鉴文献［5］中的思想,从信息融合的角度出发,提出了一种融合灰度以及纹理信息的方法,并且在此基础上设计并实现了基于子区域的区域增长方法.实验结果表明，这种方法对于特定问题有一定的效果,同时也表明，多种信息的融合可以为某些问题的解决提供新的方法,但是如何更加有效地融合多种信息则需要更深入的研究.本文在程序实现中采用了文献［2］中的部分源程序,在此表示感谢.
*　本文研究得到国家自然科学基金和国家863高科技项目基金资助.
作者简介　刘宁宁,1970年生,博士,主要研究领域为模式识别,图像处理.
　　　　　田捷,1960年生,博士，研究员，博士生导师，主要研究领域为模式识别,多媒体网络，计算机图形学，图像处理.
　　　　　胡志刚,1972年生,硕士,主要研究领域为图像处理.
　　　　　诸葛婴,1971年生,博士生,主要研究领域为医学图像处理,模式识别.
本文通讯联系人:田捷，北京 100080,中国科学院自动化研究所
作者单位：中国科学院自动化研究所　北京　100080
参考文献
1 Pal N R, Pal S K. A review on image segmentation techniques. Pattern Recognition, 1994,26(9):1277～1294
2 田捷,沙飞，张新生.实用图像处理技术.北京:电子工业出版社,1995
(Tian Jie, Sha Fei, Zhang Xin-sheng. Practical Image Processing and Analyzing Techniques. Beijing: Publishing House of Electronics Industry, 1995)
3 徐建华.图像处理与分析.北京:科学出版社,1992
(Xu Jian-hua. Image Processing and Analyzing. Beijing: Science Press, 1992)
4 包约翰［美］.自适应模式识别与神经网络.北京:科学出版社,1991
(Pao Yoh-Han. Self-adaptive Pattern Recognition and Neural Network. Beijing: Science Press, 1991)
5 戴汝为,王珏,田捷.智能系统的综合集成.杭州:浙江科技出版社,1994
(Dai Ru-wei, Wang Jue, Tian Jie. Metasynthesis of Intelligent System. Hangzhou: Zhejiang Science and Technology Publishing House, 1994)
本文1998-04-09收到原稿,1998-07-09收到修改稿
