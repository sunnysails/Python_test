软件学报
JOURNAL OF SOFTWARE
1999年　第10卷　第11期　Vol.10　No.11　1999



连续属性空间上的规则学习算法
权光日 刘文远 叶风　陈晓鹏
　　摘要　文章研究连续属性空间上的规则学习算法。首先简述了研究连续属性空间上的规则学习算法的目的和意义，并将规则学习理论中的一些基本概念推广到连续属性空间。在此基础上，研究了连续属性空间离散化问题，证明了属性空间最小离散化问题是NP困难问题，并将信息熵函数与无穷范数的概念应用到连续属性离散化问题，提出了基于信息熵的属性空间极小化算法。最后，提出了连续属性空间上的规则学习算法,并给出了数值实验结果。
　　关键词　规则学习算法，连续属性空间，信息熵，无穷范数，NP困难问题。
　　中图法分类号　TP181
A Rule Learning Algorithm on Continuous Attributes Space
QUAN Guang-ri1 LIU Wen-yuan2 YE Feng2 CHEN Xiao-peng1
1 (Weihai Campus Harbin Institute of Technology Weihai 264200)
2(Department of Computer Science and Engineering Harbin Institute of Technology Harbin 150001)
　　Abstract　The rule learning algorithm on continuous attributes space is studied in this paper. First,  thepurpose and the importance of studying rule learning algorithm on continuous attributes space are briefly introduced, and then some basic concepts in the theory of rule learning are extended to the continuous attributes space. On this basis, the authors study the problem to divide continuous attributes space, and prove that the problem of min dividing continuous attributes space is a NP hard problem. The concepts of information entropy and infinite normed apply to the problem of dividing continuous attribute space and a new algorithm of dividing continuous attribute space based on the function of information entropy are presented. At last, a rule learning algorithm on continuous attributes space is presented and the data results of the experiments are given.
　　Key words　Rule learning algorithm, continuous attribute space, information entropy, infinite normed, NP hard problem.
　　样本空间化简问题是人工智能领域中的重要研究课题.示例学习算法通过样本例子的训练产生识别函数.示例学习系统的学习速度与精度以及识别速度不仅依赖于所采用的学习算法本身,而且与训练样本集合的规模与样本空间的描述密切相关.对实际采样的数据进行筛选和改用适当的描述是提高学习速度与识别精度以及节省存储空间的重要手段.另外,样本例子的筛选与属性空间的优化描述还可以提高识别系统对输入例子噪音的鲁棒性.
　　1987年,Quinlan在研究连续属性空间上的决策树学习算法时,提出了基于信息熵的属性分割算法［1,2］.Fayyad等人在Quinlan工作的基础上提出了能够加快离散化速度的改进算法［2～4］.本文在前人工作的基础上,将信息熵函数与无穷范数的概念应用到连续属性离散化问题,提出了基于信息熵的属性空间极小化算法.其目的在于在区间分割过程中防止过分细化,以便提高学习系统的聚类能力以及识别系统对输入例子噪音的鲁棒性.在此基础上,提出了连续属性空间上的规则学习算法.
1 基本概念
　　设连续闭区间,j=1,2,...,n,为第j个属性xj的值域(取值范围),E=D1×D2×...×Dn是n维无穷向量空间,E中的元素e=(v1,v2,...,vn)叫做例子,其中vj∈Dj.设PE和NE是E的两个子集,为区别起见,分别称为正例集和反例集.
　　定义1. Dj的子集Aj称为Dj的有限个区间的并,当且仅当Aj为有限个区间(闭区间、开区间或半开半闭区间)的并,简称区间并.
　　显然,如果Aj,Bj为Dj的区间并,则Aj∪Bj,Aj∩Bj和Dj-Aj皆是Dj的区间并.
　　定义2. 选择子是形为{xj=Aj}或{xj≠Bj}的关系语句,其中Aj,Bj为满足的区间并,并且规定{xj≠Bj}={xj=Dj-Bj}.公式是1个选择子或几个选择子的合取式,记为,其中,N={1,2,...,n}.注意:(1) 对于公式L中不出现的属性,规定它取值为该属性的值域,即任何j∈N,如果,则等价于在L上逻辑乘选择子{xj=Dj};(2) 例子可以看做是公式的特殊情况统一处理,即e=(v1,v2,...,vn)={xj={vj}}.选择子S={xj=Aj}覆盖一个公式L={xj=A′j}当且仅当j∈J并且A′jAj.已知公式L={xj=Aj}及L′={xj=A′j},L覆盖L′当且仅当JJ′并且对任何j,j∈J,A′jAj.
　　定义3. 一个公式称为(对已知例子集PE∪NE)一致的,如果它不覆盖反例集NE中的任何反例.一个规则称为一致的,如果它的每一个公式都是一致的.一个规则称为完备的,如果任何一个PE中的正例子都被它覆盖,即它的某一公式覆盖.如果一个规则是一致的又是完备的,则简称一致完备的.
　　定义4. 已知反例矩阵NE和一个公式L={xj=Aj}.对NE的每一列j∈N,如果jJ,则用死元素“*”对NE中第j列的所有元素作代换;如果j∈J,则用“*”对NE中第j列属于Aj的所有元素作代换.这样得到的矩阵叫做公式L的扩张矩阵,记为EM(L).在扩张矩阵中,分别来自不同行的非死元素组成的集合叫做EM(L)的一条路.
　　易见,当定义4中的公式用正例e+代替时,就得到正例e+的扩张矩阵EM(e+).
　　定义5. 设EM(L)是一致公式L的扩张矩阵,如果在EM(L)中的某一行中只有一个非死元素,则称该元素为必选元素.
　　由于EM(L)的必选元素一定属于所有覆盖L的公式中的对应选择子,因此有着重要的作用.
　　定义6. 已知公式L={xj=Aj}及公式F={xj=Bj},则将L和F对应的选择子的取值合并得到一个新的公式,称为L和F的合并,记为LF.即LF={xj=Aj∪Bj}={xj=Aj∪Bj}.注意,对任何j,j∈N,但jJ∩J′,{xj=Aj∪Bj}={xj=Dj}省略不写.
　　定理1. 设EM(L)是一致公式L的扩张矩阵,则存在一个从EM(L)中的路到覆盖公式L的已知公式的映射.如果公式L覆盖公式L′,则EM(L)中的一条路必定也是EM(L′)中的一条路.
　　定理2. 公式L既覆盖公式A又覆盖公式B,当且仅当它覆盖AB.
　　文献［5～9］中对扩张矩阵理论进行了深入的研究,给出了扩张矩阵的重要性质,结果如下.
连续属性空间上的选择子与离散有限属性空间上的选择子的形式描述是一致的,但具体表达式是有所区别的.例如,A1={x1≠1,4}表示离散空间上的一个选择子,而B1={x1≠［0,1)∪(2,3)∪［6,8］}表示连续空间上的一个选择子.
　　定义7. 设EM(L)是一致公式C={xj=Aj}的扩张矩阵,path={xj=Pj}是EM(L)中的一条路,按下列准则生成的公式L′叫做路path在公式C的约束下生成的公式,并记为L′=L(path,C).其中Aj是区间并,Pj是离散的有限子集.
　　(1) 对于任意j∈JP,在Dj-Aj中当且仅当选定含有Pj中元素的子区间时,所得区间的并,记做Bj.
　　(2) 生成公式L′=L(path,C)={xj=Bj}.
2 属性空间化简问题的启发式算法
2.1 属性空间最小化问题是NP困难问题
　　设E=D1×D2×...×Dn是n维无穷向量空间,即第i个属性xi的值域(取值范围)(i=1,2,...,n)是连续实数闭区间,E中的元素e=(v1,v2,...,vn)叫做例子,其中vi∈Di.设PE和NE是E的两个子集,为区别起见,分别称为正例集和反例集.
　　定义8. PE,NE分别表示正例集与反例集,

称d(PE,NE)为正例集与反例集在无穷范数下的距离,简称正例集与反例集的距离.其中∈NE为任意反例子与正例子.
　　显然,如果d(PE,NE)=0,则存在一个正例子与反例子,即PE∩NE≠.当正例集PE与反例集NE满足d(PE,NE)=0时,称正例集与反例集是相交的或不可分离的.
　　为了讨论方便起见,我们规定子区间是指最小的子区间,即不含分割点的子区间.
　　定义9. 子区间的乘积空间称为极小乘积空间,简称极小空间.
　　定义10. 当一个属性空间进行划分后,每一个极小乘积空间都不同时含有正例子与反例子,则称此划分为可分离的划分;否则,称为不可分离的划分(存在一个极小乘积空间,它同时包含正例子与反例子).
　　定义11. X是E=D1×D2×...×Dn上的例子集合,Li是属于Di的一个区间,分别表示Li的左右边界,

分别叫做例子集X在属性区间Li上的上确界与下确界.
　　定义12. 对于每一个属性值区间(j=1,2,...,n),进行kj(j=1,2,...,n)等分表示第j个属性的第i个区间(即=［li-1,li),当i=n时,=［ln-1,ln］),间距,这样得到的属性空间划分称为等距划分,记做K(k1,k2,...,kn)或简记为K.
　　定理3. 如果d(PE,NE)=d＞0,则等距划分K(k1,k2,...,kn)能够分离出正例集与反例集.其中kj=［｜Dj｜/d］+1(j=1,2,...,n).证明略.
　　子空间数最小的属性区间分割问题:设E=D1×D2×...×Dn是n维无穷向量空间,即(i=1,2,...,n)是连续实数闭区间,PE,NE分别表示给定的正例集与反例集,ki(i=1,2,...,n)表示区间分割后Di区间所包含的子区间的个数,在能够分离正例集与反例集PE,NE的属性区间划分中,求出使k1.k2.....kn最小的属性区间划分.
　　分割点数最小的属性区间分割问题:设E=D1×D2×...×Dn是n维无穷向量空间,即(i=1,2,...,n)是连续实数闭区间,PE,NE分别表示给定的正例集与反例集,ki(i=1,2,...,n)表示区间分割结束后属性区间Di所包含的分割点的个数,在能够分离正例集与反例集PE,NE的属性区间划分中,求出使k1+k2+...+kn最小的属性区间划分.
　　定理4. 子空间数最小的属性区间分割问题和分割点数最小的属性区间分割问题都是NP难题.
　　为了证明上述定理4,先简单地介绍文献［10,11］中的结果(为了方便起见,在描述方面,对文献［10,11］中的结果进行了适当的改变).
　　设是二值离散的向量空间,即={0,1}(i=1,2,...,n),PE,NE分别是任意给定属性的正例集与反例集,并且PE∩NE=.
　　定义13. 是部分属性生成的乘积空间,如果存在正例子∈PE和反例子∈NE满足,则称正例集PE和反例集NE在乘积空间上是不可分离的,否则,称正例集PE和反例集NE在乘积空间E*i上是可分离的.
　　最优属性选择问题:在部分属性生成的乘积空间E*i=D*i1×D*i2×...×D*ik中,求出能够分离正例集PE和反例集NE并且维数最小的部分属性生成的乘积空间E*i.
　　引理. 最优属性选择问题是NP难题.引理的证明参看文献［10,11］.
定理4的证明:设E=D1×D2×...×Dn是连续的属性空间,其中Di=［0,1］(i=1,2,...,n);PE和NE是E上任意给定的满足下列两个条件的正例集与反例集;(1) PE∩NE=;(2) 任意正例子∈PE和反例子∈NE都有.不难看出,对于上述方式特殊选定的连续属性空间与两个条件约束下的任意正例集与反例集,子空间数最小的属性区间分割问题和分割点数最小的属性区间分割问题都等价于最优属性选择问题,所以它们都不宜解决最优属性选择问题.根据上述引理,最优属性选择问题是NP困难问题.因此,子空间数最小的属性区间分割问题和分割点数最小的属性区间分割问题都是NP难题.
2.2 基于信息熵的属性空间分割算法
2.2.1 属性区间分割算法的启发式策略准则
　　(1) 选择信息增益最大的划分点进行分割,加快分割过程,减少分割点的数目.
　　(2) 如果一个子区间的长度小于正例集与反例集之间的距离d(PE,NE),则不再进行该区间分割.这一准则能够防止区间分割过分细微,使学习后的识别系统对于输入例子具有良好的鲁棒性.
2.2.2 基于信息熵的属性区间分割算法
　　第1步. PE,NE分别表示正例集与反例集,Li(i=1,2,...,n)表示属性区间的子区间,P(L),N(L)分别表示属于L=L1×L2×...×Ln的正例子与反例子的集合,Si(i=1,2,...,n)是Di的子区间为元素的集合,分别表示Li的左右边界,分别表示例子集P(L)∪N(L)在Li上的上确界与下确界;初始化P(L)=PE,N(L)=NE,Li=Di,Si=(i=1,2,...,n).
　　第2步. 如果P(L)=或者N(L)=或者所有()＜d(PE,NE)(i=1,2,...,n),则PE=PE-P(L),NE=NE-N(L),转第8步;否则,对于每个满足()≥d(PE,NE)的属性区间进行划分,,j∈J(注:J表示满足≥d(PE,NE)的j的集合;Lj为左闭区间时Aj也是);
　　第3步. 计算每个划分的信息熵E(Lj),j∈J.

其中pAj,nAj分别表示Aj中的正例子数与反例子数;pBj,nBj表示Bj中的正例子数与反例子数;PL,NL表示属于L=L1×L2×...×Ln的正例子数与反例子数.定义I()=0.
　　第4步. 在所有划分中选择信息增益最大的划分,即选择信息熵最小的划分.最小的划分对应的属性记为r.
　　第5步. 如果I(Ar)=0且I(Br)>0,则P(L)=P(L)-P(Ar)(或者N(L)=N(L)-N(Ar)),PE=PE-P(Ar)(或者NE=NE-N(Ar)),Sr=Sr-{Lr}+{Ar}+{Br},Lr=Br;返回第2步(注意:I(Ar)=0,所以,Ar只包含L中的正例子或者只包含L中的反例子或者为空;P(Ar),N(Ar)分别表示L中属于Ar的正例子与反例子的集合).
　　第6步. 如果I(Ar)>0且I(Br)=0,则P(L)=P(L)-P(Br)(或者N(L)=N(L)-N(Br)),PE=PE-P(Br)(或者NE=NE-N(Br)),Sr=Sr-{Lr}+{Ar}+{Br},Lr=Ar;返回第2步.
　　第7步. 如果I(Ar)>0且I(Br)>0,则P(L)=P(Ar),N(L)=N(Ar),Lr=Ar,Sr=Sr-{Lr}+{Ar}+{Br},返回第2步.
　　第8步. 如果I(Ar)=0且I(Br)=0,则PE=PE-P(Ar),NE=NE-N(Ar),Sr=Sr-{Lr}+{Ar}+{Br},转第9步.
　　第9步. 如果PE≠,任意选择e+∈PE,选择包含e+的最小乘积空间L=L1×L2×...×Ln,其中Li∈Si,并且e+∈Li(i=1,2,...,n),计算P(L)和N(L),返回第2步;否则(即PE=),输出Si(i=1,2,...,n),停机.
　　定理6. 如果区间分割程序停机,则每一个属性子区间被分割成互不相交的子区间.证明略.
　　定理7. 如果d(PE,NE)=d>0,则区间分割算法在不超过次的区间分割内能够分离出正例集与反例集.证明略.
　　定理8. 如果极小空间L=L1×L2×...×Ln包含一些正例子,则C=xj=Lj},J={1,2,...,n}是一致公式,即公式C在反例集EN背景下的扩张矩阵有一条路.证明略.
　　定义14. X是E的例子集,K表示某一区间分割算法,表示区间分割算法K得到的第j个属性的第i个子区间,｜X∩｜表示在属于X的例子中,第j个属性值属于的例子数目.

称fj(t,X)为例子集X在第j个属性区间Dj上的分布函数.简称X的第j个分布函数.
　　定义15. Dj(j=1,2,...,n)的互不相交的并集D=D1∪D2∪...∪Dn上定义的函数

称F(t,X)为例子集X在D上的分布函数.简称X的分布函数.
　　定义16. X是给定的例子集,表示区间分割算法得到的第j个属性的第i个子区间,Lj表示第j个属性的子区间中至少包含一个X中例子的子区间的并,即,称L(X)=L1×L2×...×Ln为包含X的最小子空间.
　　定义17. PE和NE是给定的正例集和反例集,PE′表示正例集PE的子集,L(PE′)=L1×L2×...×Ln表示包含PE′的最小子空间.对于NE的第j(j=1,2,...,n)列中所有属于Lj的元素都用“*”代替,而得到的矩阵叫做正例子集PE′在反例集NE背景下的扩张矩阵,记做EM(PE′).
2.3 生成公式的算法
　　第1步. E=D1×D2×...×Dn是连续属性空间,PE和NE是给定的正例集和反例集,Iij表示区间分割算法得到的第j个属性的第i个子区间,PE′表示正例集PE的子集.SN表示所有只包含反例子的子区间组成的集合,即只包含扩张矩阵中非死元素的子区间组成的集合.

　　第2步. 建立PE′在反例集NE背景下的扩张矩阵EM(PE′).
　　第3步. S=,求SN.
　　第4步. 如果SN中有相邻的子区间,则合并成一个子区间,直到没有相邻的子区间为止.
　　第5步. 如果扩张矩阵中有必选元素(扩张矩阵的某一行只有一个非死元素),则在SN中选择包含该反例子的子区间,否则,在SN中选择包含反例子数最多的的子区间;NE中删去属于的反例子,S=S+{Iij}.
　　第6步. 如果反例集不空,则返回第5步;反例集空,转第7步.
　　第7步. 生成公式;停机.
3 连续属性空间上的规则学习算法
3.1 连续规则学习算法CRA
　　下面给出连续属性空间上的规则学习算法(简称连续规则学习算法,记做CRA).
　　第1步. 对于连续属性空间E=D1×D2×...×Dn,根据已知正例集PE和反例集NE,用区间分割算法进行属性区间划分.
　　PE=PE′表示正例集,NE=NE′表示反例集,EM表示扩张矩阵,F(t,PE),F(t,NE)分别表示正例集和反例集的分布函数,表示区间分割算法得到的第j个属性的第i个子区间,｜X∩｜表示在属于X的例子中,第j个属性值属于的例子数目;
　　第2步. 建立正例集和反例集的分布函数F(t,PE′)和F(t,NE′);
　　第3步. 所有中选择使(｜PE′｜-F(t,PE′))F(t,NE′)最大的i和j(其中t∈);
　　第4步. 在PE′和NE′中删除第j个特征值属于的例子,删除子区间,调整正例集和反例集的分布函数F(t,PE′)和F(t,NE′);
　　第5步. 如果NE′不空,则返回第3步;否则,调用生成公式算法;
　　第6步. 如果PE空,停机;否则,PE=PE-PE′,NE′=NE,PE′=PE,并返回第2步.
　　定理9. 如果正例集与反例集是可分离的,即d(PE,NE)=d>0,则连续规则学习算法CRA在有限步内停机,并生成一致完备规则.证明略.
3.2 学习算法的时间复杂性分析
　　P和N分别表示正例集与反例集的个数,｜Dj｜表示第j(j=1,2,...,n)个属性区间Dj的长度,d=d(PE,NE)是正例集与反例集之间的距离.
　　区间分割算法的计算时间复杂度为


　　生成公式算法被CRA算法调用的计算时间复杂度为 

　　由此可见,使正例集PE′空为止,CRA算法的计算时间复杂度为

4 故障诊断中的应用
　　表1是文献［12］中给出的汽轮机故障诊断方面的实例.本文以它为例说明基于信息熵的属性空间分割算法在连续属性空间中进行空间分割的过程,说明连续规则学习算法CRA在连续属性空间中生成识别规则的过程(即学习过程).
表1 汽轮机故障诊断实例

　SymptomFault
S1S2S3S4S5S6S7S8S9S10S11D
10.800.10.11010.10.9101
20.800.10.10.800.80.10.80.901
30.500.10.10.8010.10.70.901
40.800.20.21010.10.9101
50.500.10.10.800.90.10.70.900
60.50.900.800.80.10.90.50.10.80
70.50.900.800.80.10.50.50.20.90
80.60.700.900.50.10.80.40.10.70
90.40.700.700.50.10.70.30.10.61
100.30.900.90100.80.100.90
110.20.700.80100.8000.80
120.20.600.600.900.7000.60
130.40.40.30.6000.10.10.200.10
140.40.50.30.70.05000.10.100.10
150.40.60.40.900.800.30.100.90
160.30.80.310100.10010
170.30.40.310100.10010
180.60.30.90.30.3000000.60
190.70.30.90.30.2000000.80
200.70.60.90.6000.20.50.300.91
210.70.60.90.7000.30.60.400.81

　　本文已经证明,区间分割算法产生的极小乘积空间只包含同一类的例子,所以至少包含1个例子的极小乘积空间可看做一个例子来处理,目的在于减少参加学习的例子数目,提高学习速度与学习精度.
　　通过图1可以看出21个例子的学习问题,用区间分割算法化简成11个例子的学习问题.

类S1S2S5S7S9Contained Examples
　 
PE101211,4
011112
001213
000019
1001121,22
　 
NE001115
010016,7
100018
0100010
0000011,12,13,14,15,16,17
1000018,19

图1 包含例子的极小乘积空间
　　对于图1给出的规则学习问题,规则学习算法CRA得到的表示正例子的规则由下列3个公式组成.
［x1≠0］∧［x2≠1］∧［x5≠0］∧［x9≠0］,
［x1≠1］∧［x2≠1］∧［x7≠1］∧［x9≠0］,
［x1≠0］∧［x2≠1］∧［x5≠1］∧［x9≠0］.
把上述公式组转化成子区间形式的公式组如下:
{S1=(0.5,1］}∧{S2=［0,0.8］}∧{S5=(0.5,1］}∧{S9=(0.25,1］},
{S1=［0,0.5］}∧{S2=［0,0.8］}∧{S7=［0,0.15］∪(0.95,1］}∧{S9=(0.25,1］},
{S1=(0.5,1］}∧{S2=［0,0.8］}∧｛S5=［0,0.5］}∧{S9=(0.25,1］}.
本文在输入数据的噪音对学习系统的鲁棒性方面进行了比较实验.下面先引进几个相关的概念.
　　定义18. 噪音幅度是指,受噪音干扰的输入例子与学习样本中“最相近例子”之间的距离,即受噪音干扰的例子e*的噪音幅度等于Min{d(e*,e)｜e∈E},其中E是学习样本集合.
　　定义19. 用e*表示一个受噪音干扰的例子,e表示在学习样本中离e*最近的例子.如果e*与e的识别结果是一致的,则称e*为能够被正确识别的例子,否则,称e*为不能被正确识别的例子.
　　定义20. 算法的识别率是指,识别系统能够正确识别的例子(受噪音干扰的)数目与所有识别例子(受噪音干扰的)之间的比值.
　　我们以在采煤机故障诊断系统的研究过程中采集到的数据作为学习样本,进行了识别系统对噪音数据的鲁棒性分析实验,实验结果见表2.该学习样本的个数为1 000;输入属性空间的维数为12,属性值取值区间为［0,1］;输出属性空间的维数为1,属性值只取“正常”与“异常”两个值.识别例子集是对上述学习样本适当地进行人为输入噪音而得到的5 000个例子组成的集合.
表2 输入数据的噪音对学习系统的影响分析

受噪音干扰的幅度≤0.030.040.050.060.070.080.090.1
本文所提出算法的识别率(%)9795949290898685
Quinlan算法的识别率(%)9289858381797572

　　表2表明,在噪音数据(一定范围内的)的鲁棒性方面,本文算法比Quinlan算法有比较明显的提高.这表明,本文提出的基于信息熵的区间分割算法及其连续属性空间上的规则学习算法是非常有效的.
5 小 结
　　本文研究了连续属性空间上的规则学习算法,首先证明了属性空间最小化问题是NP困难问题,然后给出基于信息熵的属性空间极小化算法.在此基础上,提出了连续属性空间上的规则学习算法,并分析了该算法的计算时间复杂性.给出了数字实验结果,结果表明本算法是行之有效的.
基金项目：本文研究得到国家863高科技项目基金和煤炭科学基金资助.
作者简介：权光日,1962年生,博士,副教授,主要研究领域为神经网络,机器学习.
　　　　　刘文远,1968年生,博士生,讲师,主要研究领域为数据库理论,机器学习.
　　　　　叶风,1960年生,工程师,主要研究领域为人工智能逻辑基础,机器学习.
　　　　　陈晓鹏,1970年生,讲师,主要研究领域为数据库理论.
作者单位：权光日　陈晓鹏　哈尔滨工业大学威海分校 威海 264200
　　　　　刘文远　叶风　哈尔滨工业大学计算机科学与工程系 哈尔滨 150001
本文通讯联系人:权光日，威海 264200,山东省威海市哈尔滨工业大学威海分校
参考文献
　1 Quinlan J R. Inductive learning of decision trees. Machine Learning, 1986,1(1):81～106
　2 Quinlan J R. C4.5: Programs for Machine Learning. Ver.1. San Mateo, CA: Morgan Kauffmann Publisher, 1993. 170～247
　3 Fayyad U M, Irai K B. On the handling of continuous-valued attributes in decision tree generation. Machine Learning, 1992,20(8):88～102
　4 Utgoff P E, Berkman N C, Clouse J A. Decision tree induction based on efficient tree restructuring. Machine Learning, 1997,29(1):5～44
　5 洪家荣.示例学习的扩张矩阵理论.计算机学报,1991,14(6):37～42
(Hong Jia-rong. Theory of extension matrixes in learning from examples. Chinese Journal of Computers, 1991,14(6):37～42)
　6 赵美德,李星原,洪家荣.示例学习的广义扩张矩阵算法及其实现.计算机学报,1994,17(9):83～88
(Zhao Mei-de, Li Xing-yuan, Hong Jia-rong. An algorithm of generalized extension matrixes in learning from examples and implementation. Chinese Journal of Computers, 1994,17(9):83～88)
　7 权光日,洪炳熔,叶风等.集合覆盖问题的启发函数算法.软件学报,1998,9(2):156～160
(Quan Guang-ri, Hong Bing-rong, Ye Feng et al. A heuristic function algorithm for minimum set-covering problem. Journal of Software, 1998,9(2):156～160)
　8 权光日.基于规则学习的神经网络研究［博士学位论文］.哈尔滨工业大学,1998
(Quan Guang-ri. Research on neural networks based on rule learning ［Ph.D. Thesis］. Harbin Institute of Technology, 1998)
　9 Wu X D. Optimization problems in extension matrixes. Science in China (series A). 1992,35(3):363～373
　10 Chen Bin, Hong Jia-rong, Wang Ya-dong. Minimum feature subset selection problem. Journal of Computer Science and Technology, 1997,12(2):123～128
　11 陈彬,洪家荣.示例学习的最大复合问题及其算法.计算机学报,1997,20(2):128～131
(Chen Bin, Hong Jia-rong. Maximum composition problem in learning from examples and the algorithm. Chinese Journal of Computers, 1997,20(2):128～131)
　12 杨叔子,丁洪,史铁林等.基于知识的诊断推理.北京:清华大学出版社,1993.120～200
(Yang Shu-zi, Ding Hong, Shi Tie-lin et al. Diagnosic Inference Based on Knowledge. Beijing: Tsinghua University Press, 1993. 120～200)
本文1998-05-04收到原稿,1998-11-25收到修改稿
