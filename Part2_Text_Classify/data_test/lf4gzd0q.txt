软件学报
JOURNAL OF SOFTWARE
1999年　第10卷　第9期　Vol.10　No.9　1999



多类有重叠问题的扩张矩阵算法*
石大明　舒文豪　徐睿峰
摘要　示例学习是从某一概念的已给的正例集合和反例集合中归纳产生出描述所有正例并排除所有反例的该概念的一般规则，而扩张矩阵理论将寻找正例在反例背景下所满足的公式等价为在反例矩阵上找出一条生路.该文针对多类有重叠问题，改进了原有的扩张矩阵算法，引入了基于平均熵的最短公式近似解的启发式搜索，并利用势函数估计正、反例间重叠区域的概率密度函数，从而获得类间非线性判别界面.文章将此算法应用于手写汉字识别，通过分析比较，论述了改进算法的有效性.
关键词　示例学习，扩张矩阵，平均熵，势函数，手写汉字识别.
中图法分类号　TP181
An Extension Matrix Algorithm for Multi-class Problem with Overlay Area
SHI Da-ming,SHU Wen-hao,XU Rui-feng
(Department of Computer Science and Engineering Harbin Institute of Technology Harbin 150001)
SHI Da-ming,XU Rui-feng
(Department of Computing Hong Kong Polytechnic University Hong Kong)
Abstract　Learning from examples is to obtain a general rule through induction from a given set of positive and negative examples of a concept, which may describe all the positive examples, and reject all the negative examples of that concept. According to the extension matrix theory, to discover the equations which satisfy all positive examples on the background of negative examples may be considered as to find a path within the matrix of negative examples. In order to deal with the multi-class problems with overlay, an improved extension matrix algorithm has been proposed in this paper. The heuristic search based on average entropy has been used to get the approximate solutions of the shortest equation. The potential function is used to estimate the probability density function of the overlay area between positive and negative examples, so that the non-linear interfaces of the interclass areas may be obtained. The improved algorithms have been applied to handwritten Chinese character recognition and its effectiveness has been proved through comparison study and analysis.
Key words　Learning from examples, extension matrix, average entropy, potential function, handwritten Chinese character recognition.
　　示例学习是机器学习中较为成熟的分支，它是从某一概念的已给的正例集合和反例集合中归纳产生出描述所有正例并排除所有反例的该概念的一般规则，因而也被称作概念获取.根据示例学习的知识表示可分为两大类――决策树归纳与决策规则归纳［1］.前者以ID3［2］为代表，其特点是训练与分类速度都很快，适用于大规模的学习问题；后者以AE1［3］为代表，其特点是分类精度高，知识表达力强，适合于专家系统的知识自动获取.AE1以扩张矩阵（extension matrix）理论为基础.
　　当示例学习扩张矩阵理论应用于多类有重叠问题时，原有算法将造成大量的时间和空间开销，且无法解决重叠区域的规则生成.对于一个实际应用来说，各类间的重叠是普遍地客观存在的，规则学习本身不能产生一个判别界面.事实上，在80年代后期，有关概率表示的研究就开始出现在机器学习的文献上.这种表示体制有许多吸引人之处，包括清晰的概率语义层次及对不确定程度的描述能力［4］.
　　本文给出了利用平均熵的方法构造最短公式近似解的启发式搜索算法，针对类间重叠区域，构造一个非线性的势函数来估计重叠区域的样本(例子)属于某模式的条件概率密度函数.
　　本文第1节介绍了示例学习的扩张矩阵理论.第2节提出一种最简公式生成的启发式搜索算法.第3节讨论了利用势函数生成重叠区域的识别规则.第4节举例说明了在汉字识别中的应用.第5节通过实验比较算法改进前后的效果.
1　扩张矩阵理论
　　一个例子e是一组n维向量，记为e=〈x1,x2,...,xn〉，其中xj∈Dj，Dj∈N，Dj是有穷离散符号集，xj称为变元或特征.E是e的集合，PE和NE是E的两个子集，为区别起见，分别叫做正例集和反例集.
　　选择子是形为［xj≠Aj］的关系语句，其中AjDj，公式是一个选择子或几个选择子的合取式，规则是公式的析取式.
　　定义1. 一致性.正例e+在反例e-i背景下满足公式L,当且仅当e+满足L但e-i不满足L.
　　完备性.公式的析取式COV叫做PE在NE背景下的一个规则，当且仅当PE中的任何一个正例都在NE背景下至少满足COV中的一个公式.
　　从定义1的一致性与完备性可以得出，一个在NE背景下覆盖e+的公式不应含有正例e+的任何元素，但必须含有每个反例的至少一个元素.在以下的讨论中，我们将正、反例集列成矩阵的形式，并将两者视为等价：一个例子对应于相应矩阵中的一行.
　　定义2. 已知正例e+=〈x1,x2,...,xn〉及反例矩阵NE，对每一个j∈N，用“死元素”*对在NE中第j列的所有出现作代换，这样得出的矩阵叫正例在反例NE背景下的扩张矩阵，记为EM(e+)，e+称为EM(e+)的种子.
　　在扩张矩阵EM(e+)中，由分别来自不同行的m个非死元素组成的集合叫做一条路.在两个以上的扩张矩阵中，具有相同值的对应的非死元素叫做它们的公共元素，只由公共元素组成的路叫做它们的公共路.扩张矩阵具有如下性质.
　　设EM(e+)是正例e+在NE背景下的扩张矩阵，其中EM(e+)＝［rij］，e+=〈x1,x2,...,xn〉及NE＝［x-ij］，则
　　(1) 
　　(2) 扩张矩阵EM(e+)中的路同e+在NE背景下所满足的公式一一对应；
　　(3) 已知两个正例e+k＝(x+kj) 以及e+l＝(x+lj)，则NE中的元素x-ij是EM(e+k)和EM(e+l)的公共元素，当且仅当x-ij≠x+kj，并且x-ij≠x+lj.
　　由性质(2)，我们把寻找在NE背景下覆盖正例e+的公式用在相应扩张矩阵EM(e+)中搜索一条路来实现.由性质(1)及(3)，我们只需在一个反例矩阵NE中根据(1)搜索路的元素或(3)搜索公共路的元素，而完全没有必要生成一个扩张矩阵.这样，学习算法相当简单，又节省了大量存储空间.
　　 注意，以上结论均能得到严格证明［3］，但它们的成立仅对于类间不重叠问题，即任一种子的扩张矩阵不存在这样的死行：该行的所有元素为死元素.
2　最短公式近似解的启发式搜索
　　一个正例的扩张矩阵包含了所有覆盖该正例的公式，于是产生一些最优化问题.
　　(1) 最短公式问题(MCOMP)：在多项式时间内，找出一个在反例背景下覆盖一个正例的最短公式（即具有最小数目选择子的公式）.
　　(2) 最优覆盖问题(MCV)：在多项式时间内，找出一个PE在NE背景下的最优覆盖（即具有最小数目公式的规则）.
　　MCOMP和MCV问题都被证明为NP-hard［3］．这个结果反映出示例学习和自动知识获取的困难程度，并且迫使人们不得不放弃寻求最优算法的尝试而转向用各种启发式方法寻求它们的近似解.
　　AE1通过启发式方法生成一条路，对NE子集构造一个评价矩阵ENE，ENE中的元素是NE中相应变量取值相同的例子数目，正例e中的元素若在NE中出现的数目大，则将被优先搜索.当一条路生成后，AE1开始消除冗余元素.
　　AE1对MCV的近似解法为：为了生成总数较少的公式集，最好选择扩张矩阵的“最大公共路”，即在最多数目扩张矩阵中出现的路；而“最大公共元素”即在最多数目扩张矩阵中出现的元素，就最有可能在最大公共路中.因此，在扩张矩阵中，可按元素在各扩张矩阵中出现的频率选择路的结点.公式生成后，AE1开始删除冗余公式，一个公式叫做冗余的，如果它所覆盖的正例全部被其余公式的集合所覆盖.
　　任何一个例子e是一组n维向量，e=〈x1,x2,...,xn〉，扩张矩阵理论将从反例集区分出正例集的描述归结为在扩张矩阵中一条路的生成.而每组特征对区分正反例的作用是不同的.AE1首先对各正例的扩张矩阵生成各自的公共路，然后用删除冗余元素等方法寻求最大公共路.对一个多类多特征问题，这种矛盾将会更突出.
　　决策树的生成常用计算各分支带来平均熵的方法选择分支.本文将其应用到扩张矩阵中，首先引出如下定义.
　　定义3. 设E=D1×D2×...×Dn是一个C类问题的样本集，E=E1∪E2∪...∪Ec,Ei(i=1,...,C)，称为第i类问题的正例集，Dj是有穷离散符号集，j∈N.为从E中区分Ei，度量Dj上的平均熵：
　　　　　　　　　　(1)
其中nj是指Dj在符号集中取特定值的样本个数；nl是指扩张矩阵中尚未处理的行数；njk是指第k类在Dj上取特定值的样本个数.
　　优先在平均熵小的特征所在列寻找非死元素.在程序实现中按式(1)计算得到优先处理的扩张矩阵列，直到所有行处理完毕.这种方法的每一步也是贪心的，但与AE1不同的是，在生成MCOMP近似解的过程中，考虑了MCV问题，使得在生成MCV时要比AE1简捷.
3　重叠区域的规则生成
　　绝大多数实际问题都存在类间重叠现象.对于一个面临着一个庞大的样本训练集的实际的重叠问题，对样本集进行人为处理以适应精确算法的机器学习是不可行的.我们将利用已学习到的规则去识别一个汉字（或部件）看做一次试验，而极小概率的事件在一次试验中是几乎不可能发生的，在利用扩张矩阵去生成规则的过程中，一个覆盖大概率事件的公式不应该为了满足一致性去考虑反例集中极小概率事件（而这种事件极有可能是噪声），将PE分成两个真子集：PE＝PE1∪PE2.
　　定义4. PE1称为不连接子集，e∈PE1,eNE.
　　定义5. PE2称为连接子集，e∈NE,且e∈PE2.
　　易见，覆盖PE1的规则COV1具有完备性、一致性，覆盖PE2的规则COV2只具有完备性（定义1），并有如下推论［5］.
　　推论1. 生成COV1的任何一个例子，若其扩张矩阵存在死行，那么该行反例是应该删除的，生成COV2的例子可以在扩张矩阵中存在死行，死行将被越过.
　　有效地选取PE1能更好地滤除样本集自身的噪声，加快学习和识别速度.只要研究对象的模板（如正规手写楷书）是不相接的，则在大样本集下，每类聚类中心总在PE1.
3.1　基于后验概率密度的模式分类
　　现在，我们从模式识别角度来考虑应用扩张矩阵所面临的线性不可分问题.
　　模式识别的目的是要确定某一给定模式样本属于哪一类，机器学习的目的是从模式的观察值中发现某些因果关系.如果这种因果关系是确定的，那么学习得到的规则能完全确定地判别模式的隶属.但是对于许多客观现象，在同样的基本条件下可能得到不确定的观察结果，而只有在大量重复的情况下，才呈现出某种规律性.具体到利用扩张矩阵形成汉字识别规则这一问题，PE2是一个不确定区域，其“畸变”反映了不同个体的特色，由它生成的规则将直接影响分类效果优劣的评判.我们来讨论PE2中任一样本(x1,...,xn)的类别隶属问题.假设PE2中有M类.看看贝叶斯公式：
　　　　　　　　(2)
　　这里，求P(wi)是很难有意义的，因为它要求统计wi出现的概率，而实际上，不同时间、不同地区、不同行业出现某汉字的概率不尽相同；求p(e|wi)是不可能的，它要求在知道所属类别wi的情况下，具有某种特征向量为e的条件概率.然而，目前的人类文明现状决定了计算机的汉字识别相对于人的汉字识别只是在一个较粗粒度世界上处理问题，由于缺乏特征维数，会造成e的同样的取值在不同时间可能不属于同一类，我们不能产生一个规则来完全确定其隶属，而只能决定它属于各类的概率.实现这种按后验概率来进行模式分类的关键，就在于利用所给的训练样本来估计条件概率密度函数{p(wi|e),i=1,2,...,M}.
　　如果p(wi|e)>p(wj|e),j≠i,则e∈wi.
3.2　势函数生成算法
　　根据定义5，满足COV2的样本可能来自其他类别.我们通过引进势函数的概念来确定判别函数以及划分类别界面［6］.
　　定义6. 将样本看成n维模式空间的点ek=〈x1,x2,...,xn〉，若将其比作一种能量源，那么ek附近空间e点上的电位分布可看成是一个势函数K(e,ek).
　　在点ek上，电位达到峰值，而随着与该点的距离增大，电位分布迅速减小.这样，寻找模式分类的判别函数可转化为在各类电位分布之间选择合适的等位线，满足COV2的样本的分类由后验概率来完成.选择

e=〈x1,x2,...,xn〉是n维变量，ek=〈xk1,...,xkn〉是训练样本（例子）.上式满足作为势函数的3个条件，即
　　(1) MaxK(e,ek)=K(e,ek)|e=ek=1 ；
　　(2) ；
　　(3) 若‖e-ek1‖2＜‖e-ek2‖2，则K(e,ek1)>K(e,ek2).
　　设识别函数p(wi|e)可用fk(e)来近似（k为迭代次数），该函数的值域在0～1之间.为避免重复累赘，生成fk(e)的迭代算法可见下节的实际举例.由于被COV2覆盖的模式样本是随机出现的，它可能随机属于或不属于PE2，所以，fk(e)也是随机函数，随着K的增大，收敛于识别函数p(PE2|e).我们知道，覆盖COV1及COV2皆为一些合取式的析取，规则的存储是按析取项（合取式）进行的.每个合取式就可看做该类模式的一个结构模板.对于重叠区域，在理论上，迭代次数越大，fk(e)越趋近于识别函数p(PE2|e)，而考虑到存储空间有限，我们只能在存储容量与识别率二者之间取折衷.具体做法是记录PE2的均值函数及一定迭代次数区域内的指数项，fk(e)则为二者的代数和.
4　汉字识别应用举例
　　本节举例介绍如何利用扩张矩阵生成规则及势函数法估计识别函数.
　　图1是归纳学习“阿”字的正反例矩阵，这里,每个例子的特征描述为e=〈x0,x1,...,x17〉其中xi（i＝0,1,...,17）分别对应于汉字的18种轮廓基元特征，xi=0表示该特征不存在，xi=1表示该特征存在.

图1　正例矩阵和反例矩阵
　　PE1={e+1,e+2},PE2={e+3,e+4}.作e+1,e+2在反例背景下的扩张矩阵EM(e+1),EM(e+2)，如图2所示.

图2
　　为生成覆盖PE1的最短公式近似解，作PE1和NE的评价矩阵，如图3所示.

图3　PE1和NE的评价矩阵
　　依式(1），分别计算H0,H1,...,H17，其中H9最小.

　　优先处理第9维特征，依此类推，得到最短公式［x5≠1］［x9≠0］［x17≠1］，这也是EM(e+1)和EM(e+2)的最大公共路（如图2在EM(e+1)中所示）.
　　若先分别求EM(e+1)，EM(e+2)的公共路，则EM(e+2)中首先得到［x14≠0］［x17≠1］（如图2在EM(e+2)中所示）.经反复删除冗余元素才能得到最大公共路.
　　同样，也可得到连接子集PE2的完备公式，COV2=［x0≠1］［x9≠0］（如图4在EM(e+3)，EM(e+4)中所示）.
　　注意到，依照推论1，e-5被删除，在EM(e+4)中第3行死行被越过.
　　现在来生成e+3，e+4，e-3的判别函数，e+3，e+4，e-3被COV2覆盖.
　　(1) 取f0(e)=0,k=0.
　　(2) 考察e+3=〈x1,0,...,x1,17〉=〈0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0〉.因为f0(e+3)=0,取

(3) 考察e+4=〈x2,0,...,x2,17〉=〈0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,〉.因为f1(e+4)=exp(-3)＞0,取
f2(e)=f1(e).
　　(4) 考察e-3=〈x3,0,...,x3,17〉=〈0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0〉.因为f2(e-3)=exp(-3)＞0,取

则
f3(e)≈p(PE2|e).

图4
5　实验分析
　　上节举例的正反例集所组成的数据集是一个实际训练系统的一个实例集合.实验针对的字域为国标一级汉字3 755个，每个字有8个训练样本和5个测试样本.粗分类后供归纳学习的正反例集为每类80～120个汉字类别.为加强实用化程度，现正收集整理每个汉字100个样本供训练与测试.学习过程是从这个数据集归纳出识别规则，在这个过程中我们来比较生成的选择子总数、析取项（因按析取项存储规则，影响存储空间），学习时间由程序运行时间来估计；识别过程是利用所得规则去判别测试样本的所属类别，为此，我们选取该数据集所含汉字类别的各自5个测试样本来统计识别率（首选）.
　　方法1：AE1算法生成规则，且不考虑PE2，即组成PE2的所有训练样本被删除.
　　方法2：多类有重叠问题的示例学习扩张矩阵算法，但不考虑重叠区域的条件概率密度函数，即令p(PE2|e)=1.
　　方法3：多类有重叠问题的示例学习扩张矩阵算法，考虑重叠区域的条件概率密度函数.
　　比较结果见表1.
表1　算法的效果比较

　学习过程识别过程
选择子总数析取项学习时间 (s)识别率(%)
方法1 (PE1)53134635465
方法 2(PE1)537264　　
(PE2)28918942762
方法 3(PE1)537264　　
(PE2)28918942771

　　分析表1：
　　(1) 识别率的统计相当于粗分类后一个候选分支进入后级分类的统计结果.方法2考虑了重叠区域，但因重叠区域的公式生成过程中只满足完备性而不满足一致性，造成与其他类别的混淆，识别率反而比方法1低.而方法3估计了重叠区域的条件概率密度函数，识别率明显提高.这种方法对于特定对象、特定时间将更显示出其优越性.
　　(2) 方法1与方法2、3在PE1区域所生成的选择子总数相当，但析取项明显多于后两种方法，这说明了基于平均熵的最短公式近似解的启发式搜索方法对减少析取项是有效的.而这一点正是按析取项存储规则及非线性参数项所必须考虑的.
　　(3) 学习时间没有专门针对区域的统计，但亦可看出，考虑PE2所计算势函数的花费仍是值得的，并且方法3还有动态学习的优点.
　　文献［7］中提出了用基于贝叶斯估计的渐近学习算法来处理这种类间重叠问题.任何新样本按贝叶斯概率估计归类到最大可能的原有类别或分裂出另一新类别，这实际是将动态聚类方法应用于分类过程中，而本文提出的算法适用于固定类别数的问题.另外，文献［7］的分类速度远比本文算法慢.类别数越多，这种差别越明显.因其方法未区分连接子集与不连接子集，所以待定样本需尝试归类到所有其他类别，而利用本文算法能根据已学到的规则或概率密度函数确定所属类别. 
6　总 结
　　扩张矩阵理论将寻找正例在反例集背景下所满足的公式等价为在反例矩阵上找出一条生路.本文阐述了在利用扩张矩阵理论处理多类有重叠问题时，如何基于平均熵进行最短公式近似解的启发式搜索，如何利用势函数估计正、反例间重叠区域的概率密度函数，从而获得类间非线性判别界面.
*　本文研究得到国家863高科技项目基金资助.
本文通讯联系人：舒文豪，哈尔滨150001,哈尔滨工业大学计算机科学与工程系341教研室
作者简介：石大明，1971年生，博士，讲师，主要研究领域为字符识别，机器学习.
　　　　　舒文豪，1932年生，教授，主要研究领域为模式识别与人工智能.
　　　　　徐睿峰，1973年生，助教，主要研究领域为中文计算.
作者单位：石大明，舒文豪，徐睿峰（哈尔滨工业大学计算机科学与工程系　哈尔滨　150001）
　　　　　石大明，徐睿峰（香港理工大学电子计算学系　香港）
参考文献：
［1］Quinlan J R. Knowledge acquisition from structured data. IEEE Expert, 1991,6(6):32～37
［2］Quinlan J R. Induction of decision tree. Machine Learning, 1986,1(1):81～106
［3］Hong Jia-rong. AE1: an extension matrix approximate method for the general covering problem. International Journal of Computer and Information Science, 1985,14(6):421～437
［4］Pat L et al. Learning with probabilistic representations. Machine Learning, 1997,29:91～101
［5］石大明，舒文豪.势函数在示例学习扩张矩阵中的应用.模式识别与人工智能,1996,9(2):149～154
(Shi Da-ming, Shu Wen-hao. A potential function used in the extension matrix theory of machine learning from examples. Pattern Recognition and Artificial Intelligence, 1996,9(2):149～154)
［6］蔡元龙.模式识别.西安：西安电子科技大学出版社,1990
(Cai Yuan-long. Pattern Recognition. Xi'an: Xi'an University of Electronic Science and Technology Press, 1990)
［7］Anderson J R et al. Exploration of an incremental, bayesian algorithm for categorization. Machine Learning, 1992,9:275～308
收稿日期：1998-02-13，修改日期：1998-09-24
