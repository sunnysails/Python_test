软件学报
JOURNAL OF SOFTWARE
2000　Vol.11　No.4　P.502-506




一种基于照片中纹理重构三维模型的方法
杨孟洲　石教英
　摘要　如何从真实世界中获取具有真实感的三维场景模型一直是计算机图形学中的一个难点.该文给出了一种从真实世界的照片中重建三维场景模型的算法.算法根据在空间稀疏分布的不同视点处的真实场景照片中颜色纹理的一致性来建立达到照片级真实程度的三维场景模型,可用于真实世界复杂形体真实感三维模型的建立.
　关键词　基于照片建模,三维模型,一致性.
　中图法分类号　TP391
A 3D Model Reconstruction Algorithm Based on the Texture of Photos
YANG Meng-zhou　SHI Jiao-ying
（State Key Laboratory of CAD & CG　Zhejiang University　Hangzhou　310027）
Abstract　　In computer graphics, it's difficult to acquire realistic 3D scenes from the real world. In this paper, a novel 3D scene model reconstruction algorithm is presented to deal with this problem. This method reconstructs photo-realistic scene models according to the color and texture of basic input photos, which are distributed in the environment. This method can be used to reconstruct photo-realistic 3D model of complex real objects.
Key words　Photo-Based modeling, 3D model, consistency.
　　 在计算机中如何表达真实世界一直是计算机图形学研究中的难点和热点.目前主要有3类方法：基于几何造型、基于图像绘制以及几何、图像混合的方法.
　　基于几何造型的方法通常利用成熟的造型软件手工搭建模型.这种方法工作量大,结果不够精确,绘制效果也不够逼真.基于图像绘制的方法［1,2］通常用场景的一个图像集合和与之对应的深度映射来表达场景模型.基于图像绘制的主要优点是，它提供了一种对结果图像中每个像素只需要固定计算量,而与场景复杂度无关的绘制方法,但对于大规模场景则需要很多照片,使存储成为瓶颈,而且,系统能提供的场景交互手段有限,对于很多应用领域不能满足要求.把几何造型和基于图像绘制结合起来是一种非常有效的方法,最常见的例子是纹理映射的应用.
　　如果能从真实世界直接获取几何模型，将大大降低人工建模的工作量,同时将大大提高绘制的逼真度.很多学者对这种方法进行了研究.Debevec［3］给出了一种从建筑物的照片中提取有关信息重建三维模型的方法,该方法由用户交互指出建筑物的组成构件、构件之间的相互关系以及构件的一些边在照片中的对应边,根据建筑物的规整性及相互依赖性计算出照相机的参数和构件的位置、尺寸,提取出相应的纹理,搭建成具有照片级真实度的建筑物三维模型.Debevec的照片建模算法只对具有规整性和相互关系明确的建筑物类场景有效,对任意形状的场景则无能为力.另外，还有很多学者对如何从一组场景的照片中合成该场景在任意视点的新视图进行了研究,提出了立体视觉匹配［4］、体元颜色赋值［5］等方法.Seitz的体元颜色赋值模型重建方法根据场景在空间中稀疏分布的视点处照片中像素颜色之间的相关性来重建模型.Seitz首先将建模空间离散成体元,并对照片提出一个限制条件：所有照片的相机位置形成一个空间凸包,模型上任意一点都不能位于这个凸包之内,否则将导致重建算法失败；对于满足该条件的照片,根据每个体元在输入照片上的投影覆盖的像素之间的相关性给这些体元赋以颜色值,由这些有色体元来表示三维场景模型.Seitz的模型重建算法的优点是，对于模型外形的复杂程度没有限制,同时重建过程不需要人工参与；缺点是对相机位置有限制,建立的场景模型只包含场景的一部分信息,使得模型只能从有限的角度去观察,同时用体元表示模型增加了计算中的复杂度.
　　本文给出的模型重建算法与Seitz的体元颜色赋值方法都是用像素的相似性来计算模型,不同之处在于，本算法对相机的位置没有任何限制,这是优于体元颜色赋值方法之处,同时解决了模型重建中的场景之间的遮挡问题,并用面片来表示模型,使计算更为简单.
1　基于照片的三维模型重建
　　模型重建算法应该满足下面两个原则［5］.
　　(1) 照片完备性.将重建得到的三维模型重新投影,应该能精确地产生出输入图像,并且保持图像的颜色、纹理以及像素分辨率与输入图像相同.
　　(2) 视点覆盖范围宽.模型在一个宽范围内的视点处的重新投影应该精确.这就要求输入图像的视点在环境中稀疏分布.
　　将三维场景空间用3组分布于3个坐标平面上的平行平面分割开来.本算法要解决的问题就是给这些平面上分割成的面片赋以颜色值,使得对一组输入图像最大程度地满足照片完备性,即在相同视点处绘制出的图像应与原始图像尽可能地接近.
1.1　符号表示
　　假定场景和光照都是静止的,且场景的表面是朗伯表面.在这种条件下,场景表面上每一点的辐射度都具有各向同性特征,这样就可以用颜色来描述该点的辐射度.
我们以一个不透明、有色面片的有限集合S来表示三维场景表面,以F表示场景空间中由划分得到的所有面片的集合,以I表示一幅图像上所有像素的集合.同时，我们假设面片和像素无限小.
　　定义处于同一平面上的面片为一面片层Fs,定义一个平行于该面片层的平面为参考平面s,参考平面应位于重建空间外,且面片的法向量指向该参考平面.f与s的距离为‖f‖s,则
Fds={f｜‖f‖s=d}.
假设由重建空间所有面片组成集合F,即

则组成场景空间表面的所有面片都包含在F中.
1.2　辅助定义
　　定义1. 场景完备性.给定场景S和一幅视点在V的图像I,存在一面片f∈S,f对V可见,将f投影到I上得到像素p:f=S(p).记像素p∈I的颜色为color(p,I),面片f的颜色为color(f,S).假设对于一组图像I1,I2,...,In中的每一幅图像Ik及Ik上每一个像素p,都存在一个面片f∈S,使得f=S(p),我们就说场景S对这组图像完备.
　　定义2. 场景一致性.假设对于一个完备的场景S,有

我们就说场景S与图像I1,I2,...,In一致.
　　模型重建的任务是对于一组输入图像I1,I2,...,In,求取一个面片集来表示三维场景模型:

其中fp为与输入图像一致的面片.
　　为了确保重建过程是逐步一致的,即重建的每一步都与输入图像一致,我们引入不完全面片集的弱一致性.
　　定义3. 面片集弱一致性.假设一个面片集的投影与每一幅输入图像的重叠部分完全一致,我们就说它对输入图像弱一致.更确切地说,一个面片集S′中的每一个面片f∈S′,假设对于输入图像I1,I2,...,In上的像素点p∈Ii,q∈Ij,面片f=S(p)=S(q),有
color(p,Ii)=color(q,Ij)=color(f,S),
那么S′对于图像I1,I2,...,In弱一致.
　　因此，对于面片集说,场景一致性与面片集弱一致性具有以下两个性质.
　　性质1. 如果S是一致性场景,则对于每一个f∈S,f与参考平面s的距离为d,{f}∪Sds是弱一致面片集.
　　性质2. 假定场景S完备,且对每一个f∈S,f与参考平面s的距离为d,{f}∪Sds是弱一致面片集,则S是一致性场景.
1.3　遮挡问题的处理
　　对于在某一视点可见的一部分场景,当视点转移后可能会被另一部分场景遮挡,即变为不可见.在三维模型重建过程中,如何判断场景是否被遮挡对重建成功与否至关重要.如图1(a)所示,为面片f的法向量,V1,V2为视点,F为面片f的中点面片f对视点V1有可能可见；面片f对视点V2不可见.如果一个面片对一幅图像不可见,则在重建该面片时不考虑该图像.

①参考平面S;②场景
Fig.1 PLrocessing of occlusion
图1　遮挡问题的处理
　　当时,如图1(b)所示,场景表面上两点P,Q和视点V位于一条直线上,P,Q对视点V都可能可见.由于|PV|>|QV|,因此对V来说P不可见,这时,我们就说Q遮挡住了P,则在重建面片P时不考虑视点在V的图像,而在重建面片Q时要对该图像投影.
1.4　模型重建
　　重建算法根据归纳法逐步地计算出场景模型:
　　
　　F′k=f|f∈Fdks，{f}∪Fk-1的投影中f的投影与输入图像重叠部分不一致，　1≤k≤r，
(1)
　　Fk＝Fk-1-F′，　1≤k≤r，　　　　　　　　　　　　　　　　　　　　　　　　　　(2)
　　Fresult={f|f∈Fr,Fr的投影中f的投影与输入图像重叠部分一致}，
则即为所求的场景模型.
　　证明:首先我们定义F'''i＝Fdks－F′i，1≤k≤r，则有且F″1弱一致.
　　假设弱一致,由一致性性质1有F″i＝F″i－1∪F'''i弱一致.由式(1)、(2)可知因此有
　　由归纳法可得:F″r弱一致,
　　由于因此并且Fresult是弱一致面片集.很明显,由于重建过程中仅仅去掉了F中与输入图像不一致的面片,因此Fresult是完备的,由一致性性质2可知,Fresult是一致性场景,因此
□
2　算法描述
　　本节给出了从一组图像I1,I2,...,In中重建三维场景模型的算法.在上一节，我们假定将三维重建空间(空间六面体)用3组分布于3个坐标平面上的平行平面划分,在这些平面上可以得到一组面片层Fdi1si,...,Fdirsi,di1<di2<...<dir,1≤i≤6.如果一个面片f对于图像Ij没有被完全遮挡,其投影将覆盖Ij上的一部分像素,这些像素组成一个非空集合πj.在没有噪声及量化误差的情况下,一致场景S中的面片f的投影将得到一组具有相同颜色的像素集合.考虑到噪声及量化误差的影响,就要用像素集π1,π2,...,πj之间的相关性来判断一致性.相关性由各个像素集中所有像素RGB的平均值的方差来衡量,方差越小,相关性越强,反之亦然.
2.1　重建过程
　　重建空间中所有面片组成集合S1,取定重建空间某一面为参考平面,首先对距离参考平面最近的面片层进行重建,即从S1中剔除该面片层中与输入图像不一致的面片,然后对距离参考平面次近的面片层进行重建,从S1中剔除该面片层中与输入图像不一致的面片.依次对所有平行于参考平面的面片层进行重建,即剔除S1中与输入图像不一致的面片.取重建空间的另一面为参考平面,对S1中与之平行的面片层进行重建,得到面片集S2.同样地，依次将重建空间的另外4个表面作为参考平面,按照距离参考平面由近及远的次序对面片层进行重建,剔除面片层中与输入图像不一致的面片,最后得到面片集S6.将S6向每幅输入图像投影,去掉其中对所有图像都不可见的面片,得到场景的三维模型.
2.2　重建算法
　　本节给出重建算法结构如下:
　　S1=F
　　for k=1,...,6
　　　　for i=1,...,r do
　　　　　　for every f∈Fdkisk do
　　　　　　　project to I1,I2,...,In, compute λ
　　　　　　　if λ≥thresh then S1=S1-{f}
　　S=0
　　for k=1,...,6
　　　　for i=1,...,r do
　　　　　　for every f∈Fdkisk∩S1 do
　　　　　　　　project to I1,I2,...,In, compute λ
　　　　　　　　if λ＜thresh then S＝S∪｛f｝
　　λ为π1,π2,...,πj的方差,thresh是最大允许方差.thresh越小,计算结果越精确,但也可能越不完备；反之,thresh越大,计算结果越不精确,但也越完备.重建中遮挡的检测通过逐步远离参考平面的重建过程来解决,即如果f2被f1遮挡,则f1必定先被重建.具体到计算中,首先对每一幅输入图像上的每一个像素设置标志为0,表示没有一致性面片投影到该像素上.如果对面片f的投影有λ<thresh,则将其投影在输入图像上的重叠部分的像素设置标志为1,以后再有面片投影到该像素上时,就认为后者被遮挡.
3　实验结果
　　实验的输入图像由3D MAX在不同的照相机位置对一个三维犀牛模型加以渲染而获得,即任意设定了18个照相机位置,获得18幅图像.其中相机位置符合在空间中稀疏分布的原则.然后将这些图象输入重建程序,同时给出相应的相机位置和其他相机参数,开始重建.考虑到在实际照片中照相机的位置不可能很精确地获得,而且由Tsai［6］的照相机位置校正方法对真实照片校正后照相机的位置误差为3%,因此在重建时对输入图像照相机位置加了大约3%的随机扰动来模拟真实照片输入.重建后输出一个彩色面片集来表示三维模型.图2给出了重建的实验结果,其中(a)是原始输入图像中的一幅,(b)为与(a)在同一视点由重建后的模型绘制的图像,(c)为重建模型在任意视点绘制的图像.
　　算法在PⅠⅠ350兼容机上实现,软件环境为Windows 95,VC++5.0.


Fig.2　The experimental results of rhinoceros model
图2　犀牛模型实验结果
4　结 论
　　本文给出了一种新的基于照片的三维场景重建算法,根据不同照片中场景颜色纹理的相关性来建立达到照片级真实程度的三维场景模型.算法突破了体元颜色赋值方法对照相机位置的限制,使得可以对真实场景全方位拍摄照片以重建包含全部信息的三维场景模型,解决了重建中场景之间的遮挡问题,并且用面片代替体元来表示模型,使计算更为简单.算法可用于建立真实世界复杂形体的真实感三维模型.
杨孟洲（浙江大学CAD&CG国家重点实验室　杭州　310027）　
石教英（浙江大学CAD&CG国家重点实验室　杭州　310027）
参考文献
1，Levoy M, Hanrahan P. Light field rendering. In: Rushmeier H ed. Computer Graphics Proceedings, Annual Conference Series. New York: ACM SIGGRAPH, 1996. 31～42
2，Gortler S J, Grzeszczuk R, Szeliski R et al. The lumigraph. In: Rushmeier H ed. Computer Graphics Proceedings, Annual Conference Series. New York: ACM SIGGRAPH, 1996. 43～54
3，Debevec P E, Taylor C J, Jitendra Malik. Modeling and rendering architecture from photographs: a hybrid geometry-and image-based approach. In: Rushmeier H ed. Computer Graphics Proceedings Annual Conference Series. New York: ACM SIGGRAPH, 1996. 11～20
4，Maximilian Ott, Lewis J P, Ingernar Cox. Teleconferencing eye contact using a virtual camera. 1993, ftp://ftp.nj.nec.com/pub/ingemar/papers/interchi.ps.Z
5，Setiz S M, Dyer C R. Photo realistic Scene Reconstruction by Voxel Coloring. 1997, http://www.cs.wisc.edu/computer-vision/cvpr97-seitz.ps
6，Tsai R Y. A versatile camera calibration technique for high-accuracy 3D machine vision metrology using off-the-shelf cameras and lenses. IEEE Transactions on Robotics and Automation, 1987,3(4):323～344


