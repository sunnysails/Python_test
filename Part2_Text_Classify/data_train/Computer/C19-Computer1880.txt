微型机与应用
MICROCOMPUTER & ITS APPLICATIONS
2000　Vol.19　No.4　P.14-16



MATLAB下神经网络工具箱的开发和应用
刘晔　夏建生
摘 要： ＭＡＴＬＡＢ环境下神经网络工具箱的使用方法和技巧，以ＢＰ网络为例介绍了网络的初始化、训练和仿真函数，给出了网络结构的设计和图形结果的输出方法。
关键词： ＭＡＴＬＡＢ软件 神经网络 图形结果
　　人工神经网络（ANN）技术，是一种不需要选取基函数系的非线性函数逼近方法，具有自学习、自组织和自适应、固有的并行结构和并行处理、知识的分布存储、容错性等功能和特点，在复杂系统的建模问题上表现出了它的优越性。在生物、商业、环境、金融、制造业、医学、军事、通信等方面已经获得广泛应用，因此神经网络的实现就成为当务之急。神经网络的实现方案可分为基于传统计算机技术（包括：软件模拟、并行处理器阵列、传统计算机的加强等）和基于直接硬件实现（包括：VLSI技术、光学等），但目前最常用的方法还是软件模拟。由于这需要掌握计算机编程语言和较高的编程技巧，因此不利于神经网络技术的推广和应用，所以国际上许多公司和研究单位设计了通用的ANN模型库，MATLAB环境下的神经网络工具箱就是其重要代表。
　　MATLAB是MathWorks公司推出的一套高性能的数值计算和可视化软件，它集数值分析、矩阵运算、信号处理和图形显示于一体，构成了1个方便的、界面友好的用户环境。在这个环境下，对所要求解的问题，用户只需要简单地列出数学表达式，其结果便以数值或图形方式显示出来，特别是包括了被称作Toolbox（工具箱）的各类应用问题的求解工具。本文论述其中神经网络工具箱的使用方法和要点。
1　调试方法
　　设需要训练和仿真的前馈网络如图1所示。网络采用误差反传训练算法（BP算法）。

图1　网络结构
1．1 提供训练样本和权值、阈值的初始值
　　BP算法是有指导的训练，是靠调节各层的权值使网络学会训练样本所表达的规律。训练样本由输入输出对｛Pki：tkj｝组成，而i（i＝1，2，…，n，）是输入层神经元的序号，n是输入层神经元数；j（j＝1，2，…，m，）是输出层神经元的序号，m是输出层神经元数；k（k＝1，2，…，q，）是训练对的序号，显然，q的大小决定了训练样本的规模，Pki的输入方法是：先就某固定的k值，输入i的所有取值下的输入样本；再改变k值，输入i的所有取值下的输入样本；直到k＝q，输入i的所有取值下的输入样本为至tkj的输入方法与Pki相同。需要注意的是：MATLAB下的神经网络工具箱不必专门指出输入层神经元和输出层神经元的多少，而是自动地从Pki和tkj中辨认，即会默认输入层神经元数为n，输出层神经元数为m。所以Pki和tkj的给定就显得特别重要。
　　Wih是输入层至隐层的权值，h（h＝1，2，…，s1，）是隐层神经元的序号，s1是隐层神经元数，它需要在程序中给出确定的初始值，其输入方法是：就某固定的i值，输入h的所有取值下的权值；Whj是隐层至输出层的权值，其输入方法是：就某固定的h值，输入j的所有取值下的权值，bh和bj分别是隐层、输出层神经元的阈值，它们需要在程序中给出确定的初始值。
1．2　有关函数说明
　　用软件模拟BP网络时，需要用到的函数有：initff、trainbp、simuff、ploterr等，下面分别说明。
　　在设计BP网络时，只要已知输入向量p、各层的神经元数、各层神经元的传递函数，就可以利用函数initff对BP网络进行初始化。例如，1个2层（不包括输入层）的BP网络，隐层有8个神经元，传递函数为tansig（正切S型函数），输出层神经元数由目标向量t决定，传递函数为purelin（纯线性函数），该BP网络的初始化语句为：
［w1，b1，w2，b2］＝initff（p，8，′tansig′，t，′purelin′）；
　　用户在准备数据样本时，向量p应该包含所有输入值中的最大值和最小值，这样才能保证得到最佳的初始值。
　　神经网络工具箱函数trainbp、trainbpx、trainlm，用来对BP网络进行训练，它们的用法是类似的，只是采用的学习规则有所不同。函数trainbp利用标准BP学习规则训练前馈网络，使网络完成函数逼近、矢量分类和模式识别；trainbpx采用了动量法和学习率自适应调整的策略，从而提高了学习速度并增加了算法的可靠性；trainlm使用了Levenberg－Marquardt优化方法，学习时间更短，但对于复杂的问题，这种方法需要很大的存储空间。下面程序表明了trainlm的调用方法：
　　df＝5；　　　　　　　　％　训练过程显示频率
　　me＝1000；　　　　　　％　　最大训练步数
　　eg＝0．01；　　　　　　％　误差指标
　　tp＝［df me eg］；
　　［w1，b1，w2，b2，ep，tr］＝trainlm（w1，b1，′tansig′，w2，b2，′purelin′，p，t，tp）；
　　经过训练得到了新的权值矩阵w1、w2，阈值矢量b1、b2，网络的实际训练次数ep及网络训练误差平方和行矢量tr。
　　前馈网络由一系列网络层组成，每一层都从前一层得到输入数据，simuff函数可用于仿真最多3层的前馈网络：
　　a＝simuff（q，w1，b1，′tansig′，w2，b2，′purelin′）
　　上式q为输入数据，a为预测结果。
　　Ploterr（e，eg）用于绘制误差行矢量e随训练次数的变化图，同时以点线绘出误差指标eg，其纵轴为对数刻度，总的训练次数小于e的长度，e的第一个元素为网络训练前的误差。
1．3 网络结构的确定
　　神经网络的结构设计是一个非常重要但却十分复杂的问题。网络的结构设计主要指对于给定的任务：①如何选择网络层数？因为网络的输入和输出层易于确定，所以这一问题实际上就是隐层应该为几层；②每层应选多少神经元；③神经元的传递函数应如何选定。所有这些都是使用神经网络时必须加以解决的问题。但目前对此并没有一个确切的答案，MATLAB下的神经网络工具箱也不例外。
　　综合以往的研究成果，可以得到BP网络结构的一些结论：①对于3层（1个输入层、1个隐层和1个输出层）的BP网络，只要其隐层的神经元数可选，就可以任意精度逼近任何连续函数（Kolmogorov定理）；②随着所逼近函数的波动性增加，隐层的神经元数也应适当增加；③随着学习样本数的增加，隐层神经元数也应增加；④增加隐层数目可以减少各隐层的神经元数，减少陷入局部极小的机会；⑤随着网络复杂程度和学习样本数的增加，其收敛速度变慢，所以网络的规模不应随意增大。另外，作者的实践经验是：对于给定的问题，如果不得不增大网络规模时，宁愿采用较多隐层和较少神经元数的神经网络，而不应采用较少隐层和较多神经元数的神经网络。因为这样可以相对减少网络的训练时间。
2　图形结果的输出
　　图形结果的输出是软件模拟神经网络的重要步骤。根据作者使用MATLAB下神经网络工具箱的情况，除了将图形显示在计算机屏幕上，图形结果的输出还有其它几种方式。
　　（1）打印输出
　　工具箱在生成图形结果时（例如利用上述Ploterr（e，eg）函数），也同时生成该图形对应的窗口。这时可以利用窗口中的file菜单下的Page Position功能调整图形的大小和在打印纸上的位置：Paper Position：［Left Bottom Width Height］，如图2所示。再利用Print功能将图形从指定的打印机上输出。

图2　设置被打印图形
　　（2）建立图形文件输出
　　利用窗口中的file菜单下的Save As命令可以建立图形文件。该文件与一般的MATLAB文件等价，可以实现编辑、调试和运行重显图形，当然也可以打印输出。另外，有时可能在1个MATLAB程序中需要输出不止1个图形，这时可以利用MATLAB的pause命令实现运行程序的暂停，再利用Save As命令建立不同文件名的图形文件即可。
　　（3）带窗口输出
　　为了满足某种目的（例如演示和教学），有时需要输出图形的同时，输出窗口。利用Windows的剪切板可在MATLAB与其它应用程序之间交换信息。要将MATLAB的图形（带窗口）移到其它应用程序，首先按Alt－PrintScreen键，将图形（带窗口）复制到剪切板，然后激活其它应用程序，选择Edit中的Paste，就可在应用程序中得到MATLAB的图形（带窗口）。
　　（4）输出到WORD等应用程序
　　这是较为常见的输出方式。同样也是利用Windows的剪切板功能，但它不是按Alt－PrintScreen键，而是用图形窗口中Window菜单下的Copy Figure功能。首先单击图形窗口中Window菜单下的Copy Figure，然后激活其它应用程序，选择Edit中的Paste，就可在应用程序中得到MATLAB的图形（不带窗口）。
3　结论
　　人工神经网络理论和技术已经渗透到各个领域，取得了令人鼓舞的成果。本文讨论了MATLAB环境下神经网络工具箱的使用方法，重点分析了工具箱的调试技巧，给出了网络结构设计和图形结果输出方法，这些对工程实际而言具有指导作用和实用价值。
刘晔(西安交通大学电气工程学院710049)
夏建生(西安交通大学电气工程学院710049)
参考文献
１，周继成，周青山，韩飘扬．人工神经网络―第六代计算机的实现．北京：科学普及出版社，１９９３
２，Ｈａｎｓｅｌｍａｎ Ｄ，Ｌｉｔｔｌｅｆｉｅｌｄ Ｂ著，李人厚，张平安译．精通ＭＡＴ－ＬＡＢ－综合辅导与指南．西安：西安交通大学出版社，１９９８
３，楼顺天，施阳．基于ＭＡＴＬＡＢ的系统分析与设计―神经网络．西安：西安电子科技大学出版社，１９９８
４，李耀勇，郑南宁．前馈神经网络的隐结点个数与网络推广能力的关系．西安交通大学学报，１９９６；３０（９）
５，廖宁放，高稚允．ＢＰ神经网络用于函数逼近的最佳隐层结构．北京理工大学学报，１９９８；１８（４）
收稿日期：１９９９－１０－１０
