自动化学报
ACTA AUTOMATICA SINICA
1997年　第23卷　第4期　Vol.23　No.4　1997



神经计算中坐标变换的网络
模型(CMAC)的泛化特性1）
欧阳楷　陈卉　周萍　周琛
　　摘　要　在神经计算中神经网络的泛化特性是一个非常重要的内容.该文简述了小脑模型(CMAC――Cerebellar Model Areiculation Controller)的原理和学习算法，并用仿真方法讨论了在机器人使用的坐标变换关系(输入直角坐标值，输出机器手的关节角度)下CMAC的泛化性能：当泛化率为1∶100时CMAC仍能正常工作.系统的精度虽能满足需要，但是进一步提高却受到限制.本文还讨论了影响精度的各种因素及可能的改进方法.
　　关键词　泛化性能，小脑模型(CMAC)，坐标变换.
GENERALIZATION OF NEURAL NETWORK MODEL(CMAC) FOR
COORDINATE TRANSFORMATION IN NEURAL COMPUTATION
OUYANG KAI 　CHEN HUI 　ZHOU PING 　ZHOU CHEN
(Dept. of BME., Capital University of Medical Science, Beijing 100054)
Abstract　Generalization of neural network is a very important topic for coordinate transformation in neural computation. In this paper, we describe the principle of Cerebellar Model Articulation Controller(CMAC) including its learning algorithm, and discusse the generalization of CMAC through simulation of coordinate transformation (the input is position coordinate values and the output is articulation degrees of robot). The CMAC may still run well at generalization rate 1∶100. Several factors affecting the accuracy are also discussed.
Key words　 Generalization, coordinate transformation, cerebellar model articulation controller (CMAC)
1　引言
　　自Marr的视觉计算理论出版以来，计算神经科学已经成为神经科学的一个重要分支.虽然计算神经科学研究的结果只是神经系统信息加工定量描述的一种可能性，还需要生物实验的验证，但在目前神经系统所能提供的知识不完全的情况下，这种方法仍不失为一种科学探索，特别是由它提出的某些推测已成为生物实验研究的出发点和信息科学进一步发展的新观点、新方法的源泉.因此它引起了科学家的极大关注，成为当前科学的前沿之一.
　　神经计算中坐标变换是常见的一类计算任务.用数学方法或符号系统串行完成这类任务是不成问题的，而用网络方法平行地完成就不那么容易了.其根本原因在于网络完成坐标变换任务时需要对给定的网络进行训练，而且要求在全平面上对所有的点都进行训练，使之在一定的分辨率下达到精度，其训练样本集相当大.例如有人在研究视跟踪系统中的神经计算时，将转动着的视网膜的中央凹上映射的靶象转换到固定坐标系中，所用训练集的样本量达到5184，其分辨率仅为整个区域的1/2562).所以这里提出了神经网络的一个重要理论问题――泛化问题，即用较少的样本进行训练，使网络能在给定的区域内达到指定的精度.
　　最早进行泛化理论研究的是Amari［1］，他认为泛化是将输入集中样本点的给定邻域映射到输出集中映射点(与样本点对应)的某一邻域.由此可以看出泛化能力除了由精度决定外，还取决于映射方式.所以多层感知机的泛化能力是极其有限的，实践也证实了这一点.
　　本文研究一种非线性输入输出网络，它是受小脑的神经解剖生理启发而建立的，Albus称之为CMAC(Cerebellar Model Articulation Controller)［2］.这种网络的非线性映射关系与多层感知机不同.本文在简单介绍了CMAC网络的构成后，着重研究其泛化性能.
2　模型简述
2.1　模型的结构
　　CMAC中输入输出之间的映射方法是由输入激活C个单元，这C个单元内存储的数据累加构成输出.这C个单元是按“输入相邻则输出相近”的原则来编码的，即相邻的输入(输入值比较接近)所对应的C个单元中相同的较多，不相同的较少，由此可以看出，C选取得越大，对样本的映射关系的影响越大，从而可以形成较好的泛化性能.
　　简单的CMAC模型如图1所示.可以看出由输入集合S到输出集合P的映射分为两部分，即S→A(A为存放权重的地址空间)和A→P.


图1　简单的CMAC模型
2.2　激活单元的确定
2.2.1　数据的量化
　　由于输入量S多为N维模拟量，S=(S1,S2,…，SN),CMAC对这些连续量要进行量化，使之成为离散整数.例如，对于N维输入向量的每一分量Si，将其量化为1～Ri范围内的一个整数Si’：

其中　Simin　Simax分别为Si的最大值和最小值，ΔSi为量化分辨率.
2.2.2　将输入向量映射到存储器A的地址
　　首先应确定参量C，有的文献称之为概括能力，有的称为综合能力(generalization).它实质上代表输入样本间相互影响的能力.C值越大，CMAC的泛化能力越强，但学习时间势必加长.因此确定C的数值是很重要的，我们将在下面详细讨论泛化能力与C的关系.
　　S→A 的映射方法是对量化后的输入样本S的每个变量Si，根据它的值的大小，按一定规则，将其映射成C个虚拟单元地址Vi1，Vi2，…ViC，它们代表输入变量Si激活的单元.将这些虚拟单元重新组合成C个符号序列,,…，(记为A)，将它们作为存储权重的地址，其中为V1i，V2i，…，VNi的某种组合.要注意：
　　(1)将样本的输入变量Si映射成虚拟单元地址Vij的方法(或称规则)一般对最终结果没有影响，但一旦确定下来，则各变量映射的方法都应该是一致的.
　　(2)要按照数值相近、编码相近的原则来确定虚拟单元，如果两个样本的第i个变量S'i较S”i差一个单位，则对应的V’i1与V”i1相差一个单元，即相互错开一个单元.
2.2.3　由A映射到输出向量P
　　在存储器A中，每个单元中都存放着L个权重(L为输出向量的维数)，输入向量激活C个单元后，输出向量P可以按下式计算：

(1)
2.2.4　学习算法
2.2.4.1　权重的确定――有监督的学习
　　设样本为(S*，P*)，CMAC的输出为P，给定一个误差限εj，若｜－pj｜≤εj(j=1,2,…，L)，对应的权不修改；否则按下式调整权：

(2)
其中β为学习率，t为学习次数.此公式则意味着权重一次均摊到C个激活的单元上，而且不是迭代计算.
2.2.4.2　多个样本的学习
　　给定样本集S1,S2,…，SM，按训练集中样本的顺序逐个学习.每次按(2)式训练一个样本，这样对于有公共地址单元的两个样本，当第二个样本被满足时就会破坏第一个样本的输出精度.因此要对样本集进行多次循环训练，以达到各个训练样本的输出精度都得到满足.
3　仿真研究
3.1　输入输出关系
　　神经计算中的坐标变换有很多种，繁简不一.为研究泛化问题的一般性，我们选择了较复杂的，即小脑运动控制中的多自由度的关节控制所表示的坐标变换.以X(x,y,z)表示肢体要达到的空间位置坐标，以θ(θ1，…，θN)表示各关节应转过的角度，则有X=f(θ）.运动控制的坐标变换就是已知X求θ(或已知θ求X).设空间某点坐标为(x,y,z),三自由度手臂的角度为(θ1，θ2，θ3)，手臂长度为L，则

(3)
CMAC的坐标变换任务就是已知(x,y,z), 求解(θ1，θ2，θ3).
3.2　样本集的确定
　　坐标变换的输入集应遍历全部三维坐标的空间，这里为简单起见，令z为常数，则输入限于平面xy.不失一般性，可取平面内第一象限.设手臂长度为30，量化分辨率为0.1，则x、y坐标各取300个点，故输入集内点的个数为70686(1/4圆内的点).训练样本取13根辐射线(射线间夹角为7.5°)上的点，每线取60点，则样本集的数量为13×60=780.由于这些辐射线上的点经量化后有一部分是要相同的，因而实际上样本数量为703.那么在703个样本训练条件下，要求系统能在70686输入集下正常运行，泛化率定义为703∶70686≈1∶100.
3.3　精度
　　为便于研究误差，在本文的仿真研究中，坐标变换(X,θ)的关系由(3)给出，教师信号θ由(3)的逆运算给出，即θ=f-1Χ，

(4)
　　无论是输入集还是训练集，都由CMAC从X求出θ，再由θ按(3)式算出，以X和的差作为误差，结果如表1所示.
表1　误差分析　(以x坐标为例)

　最大误差最小误差平均误差均方差
样本集2.2120.0010.6050.457
输入集3.6490.0010.6770.577

　　以圆和正弦曲线为例，观察只训练输入集的1%的情况下系统的泛化能力(见图2).


图2　训练后CMAC泛化能力
(注：光滑曲线为样本曲线，不光滑曲线为CMAC输出的曲线)
3.4　影响精度的因素
　　由图2可以看出系统具有一定的泛化能力，但是比较粗糙.为提高精度，需要研究它的影响因素，从而找到提高泛化精度的办法.
　　1)提高训练精度
　　由于CMAC与多层感知机不同，其学习算法不是在最小乘方意义下的优化计算，其收敛性并无严格的证明.仿真的结果表明，在C较大、各样本间有较大交叠的情况下，训练误差在达到一定值时，将不再继续减小，表1的误差就是在此条件下列出的.
　　对CMAC学习算法中解的存在性与收敛性，目前尚无条件进行较为严格的讨论，文［3，4］中的讨论不适宜C较大、泛化能力较好的情况.根据仿真的结果可以指出，误差虽不能趋于0，但是可以减小到一定程度.
　　2)误差分析
　　根据本文所用CMAC模型及仿真方法，误差分为以下各部分：
　　(1)由于式(3)和(4)是非线性计算，故存在一定的误差；在编程中选用双精度浮点数时，此误差可以忽略(大约小于10－6).
　　(2)样本训练时遗留的误差.这与很多因素有关，如C的大小、样本的分布、输入与输出的对应关系、量化级数以及学习算法等.
　　(3)泛化误差.由于CMAC是利用各样本激活单元的重叠来获得泛化性能的，实质上是利用相邻样本的相互关系以获得输出，它显然不会是完全恰当的输出，这就带来了泛化误差.在表1中输入集较样本集的误差为大就是这个原因.
　　(4)样本序列始端误差.由于CMAC的学习算法是把样本排成序列逐个训练，训练后序样本时会改变与前序样本激活的单元交叠的单元的值，因此最后一轮样本训练完毕时，序列前面几个样本的误差就较大，这就是序列始端误差.我们把样本的顺序以辐射线为单位，将辐射线与X轴的夹角从0°变化到90°、从90°变化到0°构成不同的样本序列，其误差分布情况都是前序样本的误差较大(最前面两条辐射线上的样本中，训练时未达到训练精度的样本分别占40.3%和48.9%).
　　当角度变化从45°向两边分别达到0°和90°时，由于样本数值的变化，还会引起较大的学习振荡，误差增大.
　　(5)量化误差.CMAC对模拟输入要进行量化，然后再送入网络进行映射，因此即使网络训练得非常好，也会存在由量化引起的误差.
　　3)每个样本激活的单元数C对泛化的影响
　　C是CMAC泛化能力产生的基础，C的大小与泛化能力有很大关系：C较小泛化能力较低；C增加泛化能力增加，但训练的时间要增加，并且训练遗留的误差以及始端误差也增加，因此也不是C越大泛化性能越好(见表2).
表2　不同情况下系统30的误差(以圆曲线x坐标为例)

　　最大值最小值平均值均方差
C的大小1520.0010.0763.7120.905
302.8000.0030.8870.756
502.3730.0040.6250.579
801.9840.0050.6960.555
1202.6570.0271.2070.747
样本量7031.9840.0050.6960.555
5532.1780.0080.6460.564
3853.5510.0521.1860.872
样本分布射线1.9840.0050.6960.555
方格2.1490.0130.6990.516
圆周1.5320.0180.6610.412

　　我们的仿真研究经验表明：
　　(1)C有一个合理的数值范围，过大过小都不好，如本实验中C在50～80之间为宜；
　　(2)从经验上讲，确定C的大小以样本点所能影响的范围能覆盖非样本点、并能反映输入输出的关系为原则.表2列出了C值相同(C=80)、样本数不同时系统的误差.
　　4)　样本点的选择
　　本文利用辐射线分布构成样本集(主要考虑到输出变量为角度)，当然也可以有其它分布的样本集，如方格分布、圆周分布、随机分布等.样本分布对系统精度的影响见表2.
4　讨论
　　从以上CMAC对较复杂的非线性输入输出关系映射的仿真研究中可以看出，CMAC较多层感知机有更大的泛化能力，这对于神经网络是一个重要的、值得重视的性能.但是由于它的学习算法较为粗糙，因此系统的映射能力比较粗糙，映射的精度不高，只能说大体上具有一定的泛化非线性映射的能力.
　　所以在保证CMAC计算速度和泛化能力的前提下，进一步提高其精度就成为神经网络CMAC理论研究领域的一项挑战.作者认为，师法生物实际，可以提出以下几个改进的方向，这方面的工作也正在进行中.
　　1) 加上背角反射能力.脊椎动物运动系统脊椎神经中的背角具有某种固定的反射能力，它可以在某一小的范围内改进系统的精度.我们的初步实验表明这是有效的.
　　2) 基于小脑解剖与生理的CMAC模型的改进.人的小脑对运动控制具有较复杂的结构和机理，可以完成较为精细的、可学习的运动控制，师法生物实际将是重要的改进方向.
　　3)改进学习算法与信息存储方法.
　　4)根据映射关系确定样本集的大小与分布也是把经验知识用于学习的有效措施之一.同时C的结构及数值的分配也是值得研究的.
1)　本文受国家自然科学基金、“八六三”计划、攀登计划支持.
2)　刘林，灵长类视觉运动感知的神经计算研究；［博士论文］.北京：中国科学院生物物理所，1995.52-56.
作者简介:欧阳楷　男， 62岁， 教授， 1959年毕业于清华大学.目前是北京生物医学工程学会理事，全国生物医学工程学会、全国生物物理学会、全国自动化学会三个学会的生物信息与控制分科学会委员，《生物医学工程学报》、《北京生物医学工程》、《人工脏器与透析》三个杂志的编委.目前还承担着攀登计划、863计划课题任务.另有专著三本， 论文三十余篇.
　　陈　卉　女， 29岁， 1990年毕业于中国人民大学，现为首都医科大学生物医学工程系讲师.目前参加了攀登计划、863计划课题及其它一些科研项目，主要从事人工神经网络应用及生理系统建模仿真的研究.在国际会议上发表论文一篇，国内学术刊物上发表论文两篇.
作者单位:首都医科大学生物医学工程系　北京　100054
参考文献
［1］　Amari S L Mathematical foundations of neurocomputing. Technical Reports Faculty Engineering University of Tokyo, Japan, 1989.1―48.
［2］　Albus J S. A new approach to manipulator control: Cerebellar Model Articulation Controller (CMAC). IEEE. Trans. ASME. 1975.9.220―227.
［3］　张立明.人工神经网络模型及其应用.上海：复旦大学出版社，1993.170―184.
［4］　Wang Yin fai. A Sideris learning convergence in the Cerebellar Model Articulation Controller (CMAC). IEEE Trans. Neural Network, 1992,3(1):115―121.
收稿日期　1995-09-29
