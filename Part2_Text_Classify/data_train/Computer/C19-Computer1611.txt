信息与控制
Information and Control
1999年　第28卷　第5期　Vol.28　No.5　1999



基于多元对应分析的KNN分类器组合
韩　宏　杨静宇　胡钟山

　　摘　要： 本文提出一种基于多元相应分析的KNN分类器组合方法(MCA-KNN)，并以手写体识别 为例，用KNN分类器在同一样本集合得到的不同特征集上进行分类，再通过多元对应分析对 这些分类器的结果进行组合，以得到最终的分类结果．实验结果表明，此种分类器组合方法 能显著减少分类错误率．
　　关键词：K近邻分类器（KNN），多元对应分析, 字符识别
　　中图分类号：TP13　　　　　　文献标识码：B

COMBINATION OF KNN CLASSIFIERS BASED ON
MULTIPLE CORRESPONDENCE ANALYSIS
HAN Hong YANG Jing-yu HU Zhong-shan
(Department of Computer, Nanjing University of Science & Technolo gy, Nanjing 210094)
Abstract　This paper presents a KNN classifier combination me thod based on multiple correspondence analysis (MCA-KNN). This combination meth od is applied to written character recognition. Four kinds of features are extra cted from same sample set and four result sets are obtained from these feature s ets through KNN classifier. Through MCA-KNN, the four result sets are combined to get the final result. The experimental results in this paper demonstrate MCA -KNN's capability to reduce classifying error rate. 
Key words　KNN Classifier, Multiple Correspondence Analysis, Cha racter Recognition

1　引言
　　在模式识别中，最为常用的分类方法为KNN（K近邻）方法．KNN的基本思想是基于以下假设：相似样本的特征向量值具有相似性．其基本步骤：若对一个测试样本分类，先将其与每个被存储的原型（即聚类中心）进行比较获取相似性测度值，然后对此相似性测度值进行排序，取前K个分类结果，再利用投票原则（或加权方法）获得各类别的票数（或得分），将此样本划分为票数（或得分）最高的类别．
　　此方法存在以下问题．不相关的特征可能会对分类起负作用，这是由于其在相似性测度中所占的比重过大造成的．而且KNN在特征维数较大或存储的原型较多的情况下存在着运算量过大的现象，这对于实际中遇到的有些实时分类问题是一个较大的困难．虽然这个问题可以通过特征或原型选择得到解决，但需要很大的预处理工作．本文主要讨论KNN分类器组合．
2　分类器组合
　　分类器组合应满足下述三原则：
　　(1) 成员分类器的精确性要高．否则组合出的分类器的精确度也不会很高．
　　(2) 成员分类器的分类结果应具有多样性．因为用对相同样本犯同样分类错误的成员分类器 进行组合，对组合分类器的精确度不能带来任何提高．
　　(3) 组合分类器的效率要高．这对于用于实际应用的分类任务尤其重要．
　　然而分类器组合的最大困难就是很难同时满足精确性和多样性．
　　通常从两个方面考虑分类器组合：
　　(1) 样本的不同性质的特征集．如识别手写体，可以同时利用其统计特征和结构特征．两者 对最终的识别结果具有互补作用．
　　(2) 在样本的相同特征集上，用具有不同特性的分类器进行分类．因为在样本的不同空间上 ，它们分类结果的正确性是不同的，因此可根据不同分类器的分类效果来组合分类器．例如 ，用多个具有不同参数的神经网络分类器分别在特征集的不同子集上训练，再用一个分类器 学习这些子分类器的分类特点，从而在子分类器的分类结果上最终获得未知样本的类别．
3　基于多元对应分析的KNN分类器组合方法（MCA-KNN） 
　　假设样本共有N类，其类别由Ci, i=1,2,…,N表示．用M个KNN分类器进行分类，记为KNNi,i=1,2,…,M. 本文中M=4，每个KNN分类器的K=5．对某个测试样本Tj , KNNi分类器得到的结果为rji1,rji2,…,rjik,i=1,2,… ,M．其中rjik∈(Cl), l=1,2,…,N, k=1,2,…,K为KNNi分类器依次得到的 第l个原型所属的类别．
　　本文首先用实验样本集中的A作为原型集，B作为测试集获得分类结果R1，再用实验样 本集中的B作为原型集，A作为测试集获得分类结果R2．集合A、B的样本容量相等为n．
　　对于R1，构成以下的列联表X1=(xjl)j=1,2,…,n, l=1,2,…,(M+1)*N.构成过程为：
　　对于R1中的第j行rj11,rj12,…,rj1k,rj21,rj 22,…,rj2K,…,,rjM1,rjM2,…,rjMK,其中rj 11,rj12,…,rj1K是KNN1分类器对测试样本Bj得到的结果 ，由其获得列联表X1中的(xjl), l=1,2,…,N;
　　rj21,rj22,…,rj2K是KNN1分类器对测试样本Bj得 到的结果，由其获得列联表X1中的(xjl), l=N+1, N+2,…,2*N;
　　rjM1,rjM2,…,rjMK,是KNNM分类器对测试样本Bj得 到的结果，由其获得列联表X1中的(xjl), l=(M-1)*N+1, (M-1)*N+2,…,M*N.
对于i=1,2,…,M, k=1,2,…,K, l=(i-1)*N+1,(i-1)*N+2,…,i*N,
　　　(1)
j=1,2,…,n　　　　　　　　　　　　　　　　　　　
对于l=M*N+1,M*N+2,…,(M+1)*N,
　　　　　　　(2)
j=1,2,…,n　　　　　　　　　　　　　　　　　　　
　　若测试样本Bj的真实类别为C，假设存在一个最佳KNN分类器，记为KNN-BEST，则KNN- BEST对Bj的分类结果依次应全为C．(2)式实际上是由KNN-BEST对Bj得到的结果 获得列联表X1中的(xjl), l=M*N+1,M)*N+2,…,M*N+N.
　　对于R2,同样构成列联表X2=(xjl) j=1,2,…,n, l=1,2,…,(M+1)*N.　
　　下面用实验数据作一示例，取M=4，K=5, N=10．
　　设对测试样本T,KNNi, i=1,2,…,M获得表1中的结果．
　　示例所对应的行向量为：
(15 0 0 0 0 0 0 0 0 0, 7 0 0 0 0 0 0 0 8 0,
　14 0 1 0 0 0 0 0 0 0, 12 0 0 3 0 0 0 0 0 0,
　15 0 0 0 0 0 0 0 0 0)　　　　　　　　　　　
　　由于KNN分类器得到的分类结果与测试样本的相似度随k值增大而递减,故对结果按K ,K-1,…,1记分．由公式（1），（2）依次得到各测试样本对所有类别的得分，构成列联表中相应的行向量．
　　令X=(X1 X2)′, 对X进行多元对应分析，获取各KNN分类器对所有类别的权值 ．
表1 对类别为C1(即为数字0)的测试样本T，各KNN分类器结果

　对测试样本T
KNN分类器KNN1KNN2KNN3KNN4KNN-BEST
K值1234512345123451234512345
分类结果0000080088000020030000000
得分5432154321543215432154321
真实类别C1

　
　　训练算法如下：
(1) 对各KNN分类器的分类结果,通过公式(1),(2)得到相应的列联表．
X=(xij)n×p,n为测试样本数，p=(M+1)*N,
　　式中N为类别总数，M为参与组合的KNN分类器数目
(2) 对矩阵X，有：
　　　　　
　　　　(3)
式中diag(a)表示向量a构成的对角矩阵


(3) 对矩阵F进行奇异值分解，得到
F=U*Λ*V′　　　　　　　　　　　　　　　　　　　　 
　　　　　　　　　　　　　　　　　　　　
　　　　　　　　　　　　　　　　　(4)
(4) 对获得的投影矩阵P=(pij)P×p取P的p个行向量的前q个值作为拟合后的投 影矩阵Project，即Project=(pij)p×q．
　　对（3）中矩阵Z，有各类别的聚类中心矩阵
C=(cij)N×n, cij=Zij, i′=M*N+i,
　　式中N为类别总数，M为参与组合KNN分类器数目，n为测试样本数．
　　取C的N个行向量的前q个值作为拟合后的聚类中心矩阵Cluster，
　　即Cluster=(cij)N×q．
　　MCA-KNN分类器组合算法的实质：对训练集中的所有样本构成一个最佳KNN分类 器KNN-BEST，对参与组合的KNN分类器及KNN-BEST分类器的分类结果构成列联表．通过多元对应分析，获得在Rp（即列向量）中的q维拟合，即求得以下投影向量

使得
　　　　　　　　　(5)
达到最大，这等同于对矩阵F进行奇异值分解．为参与组合的KNN分类器在各类别上 赋予相应权值来反映它们与KNN-BEST分类器之间的关系．从训练算法中，得到的投影矩 阵Project为此权值；得到的聚类中心矩阵Cluster为此KNN-BEST分类器投影后在各 类别的数值．
　　由A、B作为原型集，各KNN算法对T进行分类得到结果RT．对第j行向量（即集合T 中第j个测试数据Tj的分类结果）
rj=(rj11,rj12,…,rj1K, rj21,rj22, …,rj2K, …,rjM1, rjM2,…,rjMK)
获得相应的N个类别的测试向量．
　　　(6)

l1=(j-1)*N+1,(j-1)*N+2,…,j*N,
l2=M*N+1,M*N+2,…,M*N+N,
j=1,2,…,M,式中N为总类别数，M为参与组合的KNN分类器个数,K 为KNN分类器中取的K值.
对数据Tj获得的N个测试向量有，
Re sulti=Testi*Project,　　　　　　　　　　　　　　　　　　
di=‖Resulti-Clusteri‖,　　　　　　　　　　　　　　　　(7)
i=1,2,…,N　　　　　　　　　　　　　　　　　　　　　　
dmin=min(di), min( )获得变量的最小值，最终的分类结果Class =min．
4　MCA-KNN分类器组合在手写体识别中的应用 
4.1 测试样本集
　　本文使用的实验样本集取自Concordia University的CENPARMI数据库中的美国邮政编码集．它大约包含17000个二值化过的数字图像（分属于数字0，1，… ，9这十类）．该邮政编码集中的样本不是均匀分布的，如其中有697个“9”，3595个“1”．为使不同分类器的分类结果具有可比性，用此数据集产生了3个标准集，每个标准集包含2000个样本，且关于类别的分布是均匀的．这三个标准集中的两个被用来作为训练集，分别记为A和B，第三个被用来测试，记为T．
　　对实验数据进行特征提取获得如下四种特征：
　　(1) Gabor特征，采用8*8采样点，4个方向(0°, 45°, 90°, 135°)．抽取特征前，图像被细化成骨架图像．每个样本用一256维的特征向量代表．
　　(2) Legendre矩，其X，Y各计算到10阶．图像的预处理过程同2．每个样本用一121维的特征向量代表．
　　(3) Pseudo-Zernike矩，其被计算到8阶．图像的预处理过程同2．每个样本用一36维的特征向量代表． 
　　(4) Zernike矩，其被计算到第9阶．抽取特征前，图像矩阵经过简单的归正处理，将矩阵中表示数字笔画的值的个数归正为300个．每个样本用一30维的特征向量代表．
4.2 KNN分类器中K的选取
　　对各特征集上KNN算法对不同的K值得到的分类结果见表2．将训练集A与B作为原型存储，再对测试集T进行投票得到结果，即将未知样本划分为获得最多票数的类别．若存在最多票数一样的情况，则判为排在前面的类别．

表2 当K(1-10)，KNN算法对四种特征集得到的分类错误率

特征集＼KNN分类错误率(%)K
12345678910
Gabor特征17.8517.8517.1016.7017.6518.0519.1018.9019.6519.75
Legendre矩8.758.758.58.88.758.98.88.959.49.5
Pseudo-Zernike矩23.6523.6522.0022.1521.2521.0020.5520.2020.8520.90
Zernike矩25.4525.4522.5021.4020.9021.1020.9021.0521.0521.55
合计18.92518.92517.52517.26317.13817.26317.33817.27517.73817.925


　　由实验可得到如下结论：
　　(1) 对于不同的特征集，随K的增大，KNN算法分类错误率非一致递减．
　　(2) K大于等于3后，KNN算法分类错误率递减较慢．
　　关于第一个结论，我们认为随着K的增大，得到的相应原型与测试样本的相似性逐渐减小，即它们之间的距离逐渐增大，该测试样本属于相应原型的可信度逐渐减小，可能带来越来越多错误类别的投票，故KNN算法分类错误率在K增大到一定程度时（如大于7后）， 开始逐渐变大．对第二个结论，由于K较大后，尽管出现错误原型的概率在增大，但鉴于前面已存在的正确原型，错误原型的影响速度较慢．
　　如表2所示，当K=5时，KNN分类器的效果最好．故在以下组合算法中，K取值为5．我们用KNN-FEATURE1，KNN-FEATURE2，KNN-FEATURE3，KNN-FEATURE4 分别代表在Gabor特征集、Legendre矩特征集、Pseudo-Zernike矩特征集及Zernike矩特征集上的KNN分类算法．
4.3 分类器组合
　　分类器组合的框架见图1．

图1　分类器组合框架
　　为充分利用样本的信息，首先用一个严格结构分类器进行预识别．并保证这一层分类的 正确性，即有很高可靠性．然后再利用样本的四种不同特征集做四个KNN分类器，对它 们进行组合，对被预识别拒识的字进行识别．
　　图1中结构分类器的识别率为53.95%，其余全部拒识．虽然拒识率很高，但是可靠性达 到100%．此结构分类器能识别出一些非常简单的数字，例如当输入图像是一个简单闭合圈时 ，它一定识为0．用来预识别的分类器不要求完善，只需能将测试样本中的一部分进行分类 ，且可靠性高即可．
　　在第二层上，对结构分类器不能识别的测试样本，用上述讨论的KNN分类器进行识别．这四个分类器得到的结果分别是与所测试样本最为相近的前五个原型的所属类别．
　　第三层是将第二层由四个KNN分类器得到的分类结果采用MCA-KNN算法进行组合， 从而得到最终的分类结果．
　　表3为MCA-KNN算法中拟合维数q变化时得到的结果．q的最大值为矩阵F（公式（3））的秩，此实验中为45．

表3 拟合维数q变化时，组合算法得到的结果

q12345678910
分类错误率（%）25.3018.9012.358.407.456.454.153.353.053.05
奇异值比率（%）6.9913.8920.3926.6332.7738.6844.3349.8755.3757.53

q11121315202530354045
分类错误率（%）3.003.003.003.003.003.003.003.003.003.00
奇异值比率（%）59.5561.5463.4367.0274.6981.2187.1592.3896.73100.0

　
　　奇异值比率=（前q个奇异值的和）/（全部奇异值的和）*100．
　　当q从1递增到11时，分类错误率由25.30%递减到3.0%；q从11递增到最大时，分类错误率保持3.0%不变．这表明q=11时，列向量的拟合结果就已达到最好的分类效果，继续增大q值，并不会提高分类的精度．
　　表4列出了以上四种KNN分类器（包含或不包含结构分类器的预处理）不同组合情况下，通过对应分析方法及简单的记分投票方法（VOTING）得到的最好结果．VOTING方法是将参与组合的KNN分类器对各类的得分分别求和，最终分类结果为得分最高的类别．
表4 不同组合情况下，对应分析方法与VOTING方法分类错误率比较 

　无结构分类器预处理结构分类器预处理
分类错误率（%）KNN-FEATURE1
KNN-FEATURE3
KNN-FEATURE4KNN-FEATURE1
KNN-FEATURE2
KNN-FEATURE3
KNN-FEATURE4KNN-FEATURE1
KNN-FEATURE3
KNN-FEATURE4KNN-FEATURE1
KNN-FEATURE2
KNN-FEATURE3
KNN-FEATURE4
VOTING方法10.956.456.353.85
对应分析方法8.504.755.203.00

　
　　表4中，对应分析方法显然优于简单记分投票方法．加入结构分类器进行预处理减小了分类错误率，这表明结构分类器与其余四种非结构特征集存在着互补的关系．
5　结论
　　基于多元对应分析的KNN分类器组合方法（MCA-KNN）通过将所有分类器的分类结果逼近一个最佳KNN分类器，给出各分类器组合时相应的权值．此算法能显著降低分类错误率，如本文实验中所得到的那样，分类错误率从参与组合效果最好的KNN-FEATURE2分 类器的8.75%降到3.00%．对于如何选取参与组合的分类器有待继续研究．
作者简介：韩　宏，女，1973年生，博士研究生．研究领域为图象处理、模式识别．
　　　　　杨静宇，男，1941年生，教授，博士生导师．研究领域为模式识别、计算机视觉．
　　　　　胡钟山，男，1973年生，博士研究生．研究领域为图象处理、模式识别．
作者单位：南京理工大学计算机系　南京　210094
参考文献
1　任若恩. 多元统计数据分析―理论、方法、实例. 1997
2　Oivind D T, Anil K J, Torfinn T. Feature Extraction Methods for Charac ter Recognition? A Survey. Pattern Recognition, 1996, 29(4):641～662 
3　宣国荣，柴佩琪. 基于巴氏距离的特征选择. 模式识别与人工智能, 1996, 9(4):324～329
4　Ching Y Suen, Christine Nadal, Raymond Legault, Tuan A. Mai and Louisa Lam. Computer Recognition of Unconstrained Handwritten Numerals. Proceedings of IEEE, 1992, 80(7):1162～1179
收稿日期：1999-04-27
