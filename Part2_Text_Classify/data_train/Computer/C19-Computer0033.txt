计算机应用
Computer Applications
1999年 第19卷 第7期  Vol.19 No.7 1999



基于注释的视频索引*
郑　鹏　李订方　刘海青

　　摘　要　本文提出了表示视频数据库的数据模型，该模型通过视频注释来描述视频数据，并利用注释建立索引，以实现按内容访问视频数据库。
　　关键词　视频数据库，镜头，注释，索引
　　
ANNOTATION-BASED INDEX IN VIDEO DATABASE

Zheng Peng　Li Dingfang　Liu Haiqing
Department of Computer Science and Technology ,
Wuhan University of Hydraulic and Electrical Engineering, Hubei*Wuhan 430072

　　Abstract　In this paper, a kind of data model to represent video database and describe video data by annotation is presented, which builds up index by the annotations so that we can access video database based on content.
　　Keywords　Video database,Shot,Annotation,Index

　　在传统的关系型数据库管理系统中，呈现给用户的数据库是表示关系的二维表，利用关键字对数据进行索引。由于关键字不可能描述视频数据的时空关系，不能完全表示语义信息，并且不支持继承性、相似性，不能进行描述间的推理，因此选择关键字集合来索引视频数据不是一种好方法。
　　考虑到视频数据的特点，我们提出了基于特征的视频索引。这种方法的主要缺点是特征缺乏语义信息，例如一些用统计矩表示的特征，使得用户在对视频数据库查询时感到不便。为此，我们提出了基于注释的视频索引。
1　数据模型与上下文
　　在视频流中有两个固有的抽象层次：整个视频流和单个帧。对大多数应用来说整个视频流作为一个抽象层次太粗糙；另一方面，一个单独的帧很少是感兴趣的单元。于是我们把原始视频流按镜头(shot)分段［1］，以镜头作为视频流的基本单位，把这些基本单位存储在媒体上，形成一个存储的媒体段库。镜头是摄像机在一次拍摄过程中所记录下的视频帧序列，加上特征和注释组成镜头库。有了镜头库后，我们就可根据应用的需要建立视频文档库，形成用户视图。视频文档可以是场景、序列、复合单元等。这些视频区间在不同的精细程度上反映了视频信息。我们把视频数据库系统看成是由存储的媒体段、镜头和视频文档三个层次组成。对镜头库和视频文档库都可采用如下的数据模型：
　　V ：视频区间：(oid,tb,te)
　　　：特 征：(F1,F2,…Fn)
　　　：注 释：(A1,A2,…Am) 　(1)
　　其中，oid表示区间标识符，tb,te分别表示起始帧与终止帧。
　　对镜头库而言，特征是指每个镜头所独有的，与其它镜头没有关系,我们称之为上下文无关；注释也是针对单个镜头进行的。对视频文档库而言，特征考虑到了视频区间之间的关系，离开了视频区间的环境，特征也就不复存在。对视频区间的注释依赖于上下文。而这一点正好反映了视频数据的时间维度。
　　正如前面数据模型中指出的那样，视频数据库中包含许多不同类型的信息。我们采用面向对象的方法，把每一类信息都定义成对象，相同类型的对象构成一个集合，几个集合的集合就构成视频数据库。为了便于浏览和查询，需要引入现实世界的关系实体对媒体流进行解释。视频文档可以包含结构信息，结构可用结构元素集来表示，每一个元素可识别一个视频流区间。层次模型支持对视频结构的描述，这样允许用户在不同的层次上对视频进行检索，以满足不同用户的要求。
　　为了对基本段进行注释，引入几个语义实体：
　　人物： 包括姓名、年龄、国籍和职业等属性。
　　地点： 包括国名、省名和城市名等属性。
　　事件： 包括事件类型、事件发生的时间和对事件的描述等属性。
　　物理对象： 包括对象类型和对象描述的属性。
　　由于视频数据还具有时间维度，所以在进行注释时，还应考虑视频段之间的关系，即视频段所处的上下文(context)［2］。因为对视频数据的注释与其上下文密切相关，对上下文的控制显得尤为重要。建立视频数据库的目的是有效地管理和利用视频，由于视频数据量的庞大，对视频段的共享和重用也是十分必要的。为此，我们把上下文分成三个层次：
　　基本上下文： 对存储的媒体段中的单个段进行的描述。存储的媒体段是真正存储在物理设备上的视频实体。



图1　基于注释的索引

　　初级上下文： 把存储的媒体段进行编辑合成后，形成视频文档，视频文档是呈现给用户的视图，是逻辑上的。对视频文档的访问最后要映射到存储的媒体段上，物理存储与逻辑视图的分离有利于视频数据的共享和重用。对一个具体的视频文档进行的描述称为初级上下文。
　　次级上下文： 一个视频文档(D1)中的某些段被另一视频文档(D2)所共享，即出现在另一视频文档(D2)中，则在视频文档(D2)中对此共享段的描述称为视频文档(D1)的次级上下文。
　　提出三级上下文的原因是这样做可以更好地控制视频数据的共享和对视频数据的描述。在基本上下文中的注释，可被使用此存储媒体段的所有视频文档“看”到和共享，在某一视频文档的初级上下文中的注释不会与其它视频文档的初级上下文中的注释混淆，即使两者使用了某些相同的存储媒体段，在必要时，可使用次级上下文来搜索与当前上下文中的注释使用了相同存储媒体段的其它视频文档。
2　视频注释
　　我们可以利用这几个语义实体对基本段进行注释。注释就是与特定视频段相关的语义属性集。不同的视频段，其注释是不同的。
　　在存储的媒体流中，ms是存储的媒体段，(ms.SID)是其标识符，(ms.TS)是其绝对的起始时间，(ms.TE)是其绝对的终止时间，(ms.TimeUnitSize)是其时间坐标系统的时间单位。存储的媒体段的集合称为MS―Set。
　　视频文档中的每一段和每一个镜头都称为视频流区间(StreamInt)，所有的视频流区间构成视频流区间集(StreamInt―Set)。StreamInt定义如下：
　　StreamInt＝(oid,MS―ref,TS,TE) 其中
　　　TS≤TE∧存在ms∈MS―Set
　　　(MS―ref=ms∧ms.TS≤TS∧ms.TE≥TE)　　　(2)
　　MS―ref是ms的标识符，oid是视频流区间的标识符，TS、TE分别表示起始帧和终止帧。从(1)式可以看出视频流区间可以是相关视频存储段的一部分或全部。在此基础上定义视频注释如下：
　　Annot=(oid,a1,a2,...,am,SI―ref) 其中
　　SI―ref∈StreamInt―Set∧a1,a2,...,am
　　　　是具体的属性类型　　　　　　　(3)
　　在视频数据库中，除了语义注释可以帮助理解视频信息以外，视频结构也有助于理解视频信息。前面提出的层次模型支持对视频结构的解释。一般可把视频文档定义成镜头、场景、序列和复合单元。结构元素的一个重要方面就是能够表示不同精细程度的上下文，如表示镜头的上下文比表示序列的上下文要精细一些。
　　结构元素是结构元素集合(Struct―Set)的一个成员，定义如下：
　　StructComp=(oid,Type,a1,a2,...,am,SI―ref) 其中
　　　SI―ref∈StreamInt―Set
　　　∧эvs∈VS―Set(SI―ref.MS―ref=vs)
　　　∧Type∈{cu,seq,sence,shot}∧a1,a2,...,am是类型说明的属性　　　(4)
　　视频结构是与视频文档相关的，与存储的媒体段不相关，在我们的模型中指出了视频流有镜头、场景、序列、复合单元等。
　　图1说明了基于注释的索引。其中Ⅰ、Ⅱ是两个视频文档，Ⅲ、Ⅳ、Ⅴ是存储的视频段，（Ⅲ，50，950），（Ⅳ，100，700），（Ⅴ，200，600）分别是Ⅲ、Ⅳ、Ⅴ的基本上下文，（Ⅰ，100，1600），（Ⅱ，200，1201）分别是Ⅰ、Ⅱ的初级上下文，由于Ⅰ、Ⅱ中对Ⅳ共享，它们互为次级上下文，次级上下文是一个虚拟的概念，所有的描述都是在基本上下文和初级上下文中完成。
　　注释a1-a6是在存储的媒体段上的基本上下文进行的，Rowe等［2］使用术语感觉索引(sensory indexes)表示这类信息，这类索引是独立于初级上下文的，反映了视频的语法信息。注释a7、a8是在视频文档的初级上下文中进行的，Rowe等使用术语主题索引来表示这类信息，这类索引依赖于用户对视频材料的使用方式和目的，反映了视频的语义信息。
3　结束语
　　随着多媒体、电视、通信技术的迅猛发展，视频数据日益增多。为了有效地管理和利用视频数据，人们自然想到建立视频数据库。由于视频数据的信息含量非常丰富，结构复杂多样，因此要想有效地检索视频数据，必须对视频数据建立索引。世界上对视频数据库的研究只是最近几年的事，目前还没有成熟的商用系统。我们根据目前机器视觉的技术水平和视频数据的特点，提出了一种利用注释建立视频数据索引的方法。这一方法的优点是很好地反映了视频数据的语义特性，缺点是注释往往要手工进行，这就使得注释的成本较高并且与注释者有关，这一问题的解决依赖于人工智能的新进展。由于视频数据库是一个较新的领域，其索引方法有待进一步研究。
　　
　　郑　鹏　博士研究生。 研究方向：机器视觉与图像处理。
　　* 本文受国家电力公司计算机应用重点学科专项基金的资助。
　　作者单位：郑　鹏　李订方　刘海青（武汉水利电力大学计算机科学与技术系　湖北．武汉430072）
参考文献
［1］　Arun Hampapur. Design Video Data Management System. Ph.D thesis, 1995
［2］　L.A.Rowe, J.S.Boreczky，C.A.Eads. Indexes for User Access to Large Video Databases. In Proceedings of the IS&T/SPIE Symposium on Electronic Imaging Science and Technology, Conference on Storage and Retrieval for Image and Video DatabasesⅡ, San Jose,CA,February 1994
［3］　Rune Hjelsvold. Sharing and Reuse of Video Information. In Proceedings of the ACM Multimedia′94 Conference Workshop on Multimedia Database Management Systems,San Francisco, California, October 1994
收稿日期:1999-01-22
